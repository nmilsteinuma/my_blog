<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ad0000; } /* Alert */
code span.an { color: #5e5e5e; } /* Annotation */
code span.at { } /* Attribute */
code span.bn { color: #ad0000; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007ba5; } /* ControlFlow */
code span.ch { color: #20794d; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #5e5e5e; } /* Comment */
code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
code span.dt { color: #ad0000; } /* DataType */
code span.dv { color: #ad0000; } /* DecVal */
code span.er { color: #ad0000; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #ad0000; } /* Float */
code span.fu { color: #4758ab; } /* Function */
code span.im { } /* Import */
code span.in { color: #5e5e5e; } /* Information */
code span.kw { color: #007ba5; } /* Keyword */
code span.op { color: #5e5e5e; } /* Operator */
code span.ot { color: #007ba5; } /* Other */
code span.pp { color: #ad0000; } /* Preprocessor */
code span.sc { color: #5e5e5e; } /* SpecialChar */
code span.ss { color: #20794d; } /* SpecialString */
code span.st { color: #20794d; } /* String */
code span.va { color: #111111; } /* Variable */
code span.vs { color: #20794d; } /* VerbatimString */
code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
</style>


  <!--radix_placeholder_meta_tags-->
<title>Noah Milstein DACSS Blog: ML Homework 2</title>

<meta property="description" itemprop="description" content="A short description of the post."/>


<!--  https://schema.org/Article -->
<meta property="article:published" itemprop="datePublished" content="2022-03-29"/>
<meta property="article:created" itemprop="dateCreated" content="2022-03-29"/>
<meta name="article:author" content="Noah Milstein"/>

<!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
<meta property="og:title" content="Noah Milstein DACSS Blog: ML Homework 2"/>
<meta property="og:type" content="article"/>
<meta property="og:description" content="A short description of the post."/>
<meta property="og:locale" content="en_US"/>
<meta property="og:site_name" content="Noah Milstein DACSS Blog"/>

<!--  https://dev.twitter.com/cards/types/summary -->
<meta property="twitter:card" content="summary"/>
<meta property="twitter:title" content="Noah Milstein DACSS Blog: ML Homework 2"/>
<meta property="twitter:description" content="A short description of the post."/>

<!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->

<script type="text/json" id="radix-rmarkdown-metadata">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","date","output"]}},"value":[{"type":"character","attributes":{},"value":["ML Homework 2"]},{"type":"character","attributes":{},"value":["A short description of the post."]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url"]}},"value":[{"type":"character","attributes":{},"value":["Noah Milstein"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":[]}},"value":[]}]}]},{"type":"character","attributes":{},"value":["2022-03-29"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained"]}},"value":[{"type":"logical","attributes":{},"value":[false]}]}]}]}
</script>
<!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["ml-homework-2_files/figure-html5/unnamed-chunk-102-1.png","ml-homework-2_files/figure-html5/unnamed-chunk-105-1.png","ml-homework-2_files/figure-html5/unnamed-chunk-106-1.png","ml-homework-2_files/figure-html5/unnamed-chunk-107-1.png","ml-homework-2_files/figure-html5/unnamed-chunk-108-1.png","ml-homework-2_files/figure-html5/unnamed-chunk-112-1.png","ml-homework-2_files/figure-html5/unnamed-chunk-116-1.png","ml-homework-2_files/figure-html5/unnamed-chunk-16-1.png","ml-homework-2_files/figure-html5/unnamed-chunk-21-1.png","ml-homework-2_files/figure-html5/unnamed-chunk-26-1.png","ml-homework-2_files/figure-html5/unnamed-chunk-4-1.png","ml-homework-2_files/figure-html5/unnamed-chunk-45-1.png","ml-homework-2_files/figure-html5/unnamed-chunk-46-1.png","ml-homework-2_files/figure-html5/unnamed-chunk-47-1.png","ml-homework-2_files/figure-html5/unnamed-chunk-92-1.png","ml-homework-2_files/figure-html5/unnamed-chunk-96-1.png","ml-homework-2_files/figure-html5/unnamed-chunk-97-1.png"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
<meta name="distill:offset" content="../.."/>

<script type="application/javascript">

  window.headroom_prevent_pin = false;

  window.document.addEventListener("DOMContentLoaded", function (event) {

    // initialize headroom for banner
    var header = $('header').get(0);
    var headerHeight = header.offsetHeight;
    var headroom = new Headroom(header, {
      tolerance: 5,
      onPin : function() {
        if (window.headroom_prevent_pin) {
          window.headroom_prevent_pin = false;
          headroom.unpin();
        }
      }
    });
    headroom.init();
    if(window.location.hash)
      headroom.unpin();
    $(header).addClass('headroom--transition');

    // offset scroll location for banner on hash change
    // (see: https://github.com/WickyNilliams/headroom.js/issues/38)
    window.addEventListener("hashchange", function(event) {
      window.scrollTo(0, window.pageYOffset - (headerHeight + 25));
    });

    // responsive menu
    $('.distill-site-header').each(function(i, val) {
      var topnav = $(this);
      var toggle = topnav.find('.nav-toggle');
      toggle.on('click', function() {
        topnav.toggleClass('responsive');
      });
    });

    // nav dropdowns
    $('.nav-dropbtn').click(function(e) {
      $(this).next('.nav-dropdown-content').toggleClass('nav-dropdown-active');
      $(this).parent().siblings('.nav-dropdown')
         .children('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $("body").click(function(e){
      $('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $(".nav-dropdown").click(function(e){
      e.stopPropagation();
    });
  });
</script>

<style type="text/css">

/* Theme (user-documented overrideables for nav appearance) */

.distill-site-nav {
  color: rgba(255, 255, 255, 0.8);
  background-color: #0F2E3D;
  font-size: 15px;
  font-weight: 300;
}

.distill-site-nav a {
  color: inherit;
  text-decoration: none;
}

.distill-site-nav a:hover {
  color: white;
}

@media print {
  .distill-site-nav {
    display: none;
  }
}

.distill-site-header {

}

.distill-site-footer {

}


/* Site Header */

.distill-site-header {
  width: 100%;
  box-sizing: border-box;
  z-index: 3;
}

.distill-site-header .nav-left {
  display: inline-block;
  margin-left: 8px;
}

@media screen and (max-width: 768px) {
  .distill-site-header .nav-left {
    margin-left: 0;
  }
}


.distill-site-header .nav-right {
  float: right;
  margin-right: 8px;
}

.distill-site-header a,
.distill-site-header .title {
  display: inline-block;
  text-align: center;
  padding: 14px 10px 14px 10px;
}

.distill-site-header .title {
  font-size: 18px;
  min-width: 150px;
}

.distill-site-header .logo {
  padding: 0;
}

.distill-site-header .logo img {
  display: none;
  max-height: 20px;
  width: auto;
  margin-bottom: -4px;
}

.distill-site-header .nav-image img {
  max-height: 18px;
  width: auto;
  display: inline-block;
  margin-bottom: -3px;
}



@media screen and (min-width: 1000px) {
  .distill-site-header .logo img {
    display: inline-block;
  }
  .distill-site-header .nav-left {
    margin-left: 20px;
  }
  .distill-site-header .nav-right {
    margin-right: 20px;
  }
  .distill-site-header .title {
    padding-left: 12px;
  }
}


.distill-site-header .nav-toggle {
  display: none;
}

.nav-dropdown {
  display: inline-block;
  position: relative;
}

.nav-dropdown .nav-dropbtn {
  border: none;
  outline: none;
  color: rgba(255, 255, 255, 0.8);
  padding: 16px 10px;
  background-color: transparent;
  font-family: inherit;
  font-size: inherit;
  font-weight: inherit;
  margin: 0;
  margin-top: 1px;
  z-index: 2;
}

.nav-dropdown-content {
  display: none;
  position: absolute;
  background-color: white;
  min-width: 200px;
  border: 1px solid rgba(0,0,0,0.15);
  border-radius: 4px;
  box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.1);
  z-index: 1;
  margin-top: 2px;
  white-space: nowrap;
  padding-top: 4px;
  padding-bottom: 4px;
}

.nav-dropdown-content hr {
  margin-top: 4px;
  margin-bottom: 4px;
  border: none;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.nav-dropdown-active {
  display: block;
}

.nav-dropdown-content a, .nav-dropdown-content .nav-dropdown-header {
  color: black;
  padding: 6px 24px;
  text-decoration: none;
  display: block;
  text-align: left;
}

.nav-dropdown-content .nav-dropdown-header {
  display: block;
  padding: 5px 24px;
  padding-bottom: 0;
  text-transform: uppercase;
  font-size: 14px;
  color: #999999;
  white-space: nowrap;
}

.nav-dropdown:hover .nav-dropbtn {
  color: white;
}

.nav-dropdown-content a:hover {
  background-color: #ddd;
  color: black;
}

.nav-right .nav-dropdown-content {
  margin-left: -45%;
  right: 0;
}

@media screen and (max-width: 768px) {
  .distill-site-header a, .distill-site-header .nav-dropdown  {display: none;}
  .distill-site-header a.nav-toggle {
    float: right;
    display: block;
  }
  .distill-site-header .title {
    margin-left: 0;
  }
  .distill-site-header .nav-right {
    margin-right: 0;
  }
  .distill-site-header {
    overflow: hidden;
  }
  .nav-right .nav-dropdown-content {
    margin-left: 0;
  }
}


@media screen and (max-width: 768px) {
  .distill-site-header.responsive {position: relative; min-height: 500px; }
  .distill-site-header.responsive a.nav-toggle {
    position: absolute;
    right: 0;
    top: 0;
  }
  .distill-site-header.responsive a,
  .distill-site-header.responsive .nav-dropdown {
    display: block;
    text-align: left;
  }
  .distill-site-header.responsive .nav-left,
  .distill-site-header.responsive .nav-right {
    width: 100%;
  }
  .distill-site-header.responsive .nav-dropdown {float: none;}
  .distill-site-header.responsive .nav-dropdown-content {position: relative;}
  .distill-site-header.responsive .nav-dropdown .nav-dropbtn {
    display: block;
    width: 100%;
    text-align: left;
  }
}

/* Site Footer */

.distill-site-footer {
  width: 100%;
  overflow: hidden;
  box-sizing: border-box;
  z-index: 3;
  margin-top: 30px;
  padding-top: 30px;
  padding-bottom: 30px;
  text-align: center;
}

/* Headroom */

d-title {
  padding-top: 6rem;
}

@media print {
  d-title {
    padding-top: 4rem;
  }
}

.headroom {
  z-index: 1000;
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
}

.headroom--transition {
  transition: all .4s ease-in-out;
}

.headroom--unpinned {
  top: -100px;
}

.headroom--pinned {
  top: 0;
}

/* adjust viewport for navbar height */
/* helps vertically center bootstrap (non-distill) content */
.min-vh-100 {
  min-height: calc(100vh - 100px) !important;
}

</style>

<script src="../../site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<link href="../../site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet"/>
<link href="../../site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet"/>
<script src="../../site_libs/headroom-0.9.4/headroom.min.js"></script>
<script src="../../site_libs/autocomplete-0.37.1/autocomplete.min.js"></script>
<script src="../../site_libs/fuse-6.4.1/fuse.min.js"></script>

<script type="application/javascript">

function getMeta(metaName) {
  var metas = document.getElementsByTagName('meta');
  for (let i = 0; i < metas.length; i++) {
    if (metas[i].getAttribute('name') === metaName) {
      return metas[i].getAttribute('content');
    }
  }
  return '';
}

function offsetURL(url) {
  var offset = getMeta('distill:offset');
  return offset ? offset + '/' + url : url;
}

function createFuseIndex() {

  // create fuse index
  var options = {
    keys: [
      { name: 'title', weight: 20 },
      { name: 'categories', weight: 15 },
      { name: 'description', weight: 10 },
      { name: 'contents', weight: 5 },
    ],
    ignoreLocation: true,
    threshold: 0
  };
  var fuse = new window.Fuse([], options);

  // fetch the main search.json
  return fetch(offsetURL('search.json'))
    .then(function(response) {
      if (response.status == 200) {
        return response.json().then(function(json) {
          // index main articles
          json.articles.forEach(function(article) {
            fuse.add(article);
          });
          // download collections and index their articles
          return Promise.all(json.collections.map(function(collection) {
            return fetch(offsetURL(collection)).then(function(response) {
              if (response.status === 200) {
                return response.json().then(function(articles) {
                  articles.forEach(function(article) {
                    fuse.add(article);
                  });
                })
              } else {
                return Promise.reject(
                  new Error('Unexpected status from search index request: ' +
                            response.status)
                );
              }
            });
          })).then(function() {
            return fuse;
          });
        });

      } else {
        return Promise.reject(
          new Error('Unexpected status from search index request: ' +
                      response.status)
        );
      }
    });
}

window.document.addEventListener("DOMContentLoaded", function (event) {

  // get search element (bail if we don't have one)
  var searchEl = window.document.getElementById('distill-search');
  if (!searchEl)
    return;

  createFuseIndex()
    .then(function(fuse) {

      // make search box visible
      searchEl.classList.remove('hidden');

      // initialize autocomplete
      var options = {
        autoselect: true,
        hint: false,
        minLength: 2,
      };
      window.autocomplete(searchEl, options, [{
        source: function(query, callback) {
          const searchOptions = {
            isCaseSensitive: false,
            shouldSort: true,
            minMatchCharLength: 2,
            limit: 10,
          };
          var results = fuse.search(query, searchOptions);
          callback(results
            .map(function(result) { return result.item; })
          );
        },
        templates: {
          suggestion: function(suggestion) {
            var img = suggestion.preview && Object.keys(suggestion.preview).length > 0
              ? `<img src="${offsetURL(suggestion.preview)}"</img>`
              : '';
            var html = `
              <div class="search-item">
                <h3>${suggestion.title}</h3>
                <div class="search-item-description">
                  ${suggestion.description || ''}
                </div>
                <div class="search-item-preview">
                  ${img}
                </div>
              </div>
            `;
            return html;
          }
        }
      }]).on('autocomplete:selected', function(event, suggestion) {
        window.location.href = offsetURL(suggestion.path);
      });
      // remove inline display style on autocompleter (we want to
      // manage responsive display via css)
      $('.algolia-autocomplete').css("display", "");
    })
    .catch(function(error) {
      console.log(error);
    });

});

</script>

<style type="text/css">

.nav-search {
  font-size: x-small;
}

/* Algolioa Autocomplete */

.algolia-autocomplete {
  display: inline-block;
  margin-left: 10px;
  vertical-align: sub;
  background-color: white;
  color: black;
  padding: 6px;
  padding-top: 8px;
  padding-bottom: 0;
  border-radius: 6px;
  border: 1px #0F2E3D solid;
  width: 180px;
}


@media screen and (max-width: 768px) {
  .distill-site-nav .algolia-autocomplete {
    display: none;
    visibility: hidden;
  }
  .distill-site-nav.responsive .algolia-autocomplete {
    display: inline-block;
    visibility: visible;
  }
  .distill-site-nav.responsive .algolia-autocomplete .aa-dropdown-menu {
    margin-left: 0;
    width: 400px;
    max-height: 400px;
  }
}

.algolia-autocomplete .aa-input, .algolia-autocomplete .aa-hint {
  width: 90%;
  outline: none;
  border: none;
}

.algolia-autocomplete .aa-hint {
  color: #999;
}
.algolia-autocomplete .aa-dropdown-menu {
  width: 550px;
  max-height: 70vh;
  overflow-x: visible;
  overflow-y: scroll;
  padding: 5px;
  margin-top: 3px;
  margin-left: -150px;
  background-color: #fff;
  border-radius: 5px;
  border: 1px solid #999;
  border-top: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion {
  cursor: pointer;
  padding: 5px 4px;
  border-bottom: 1px solid #eee;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion:last-of-type {
  border-bottom: none;
  margin-bottom: 2px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item {
  overflow: hidden;
  font-size: 0.8em;
  line-height: 1.4em;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item h3 {
  font-size: 1rem;
  margin-block-start: 0;
  margin-block-end: 5px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-description {
  display: inline-block;
  overflow: hidden;
  height: 2.8em;
  width: 80%;
  margin-right: 4%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview {
  display: inline-block;
  width: 15%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img {
  height: 3em;
  width: auto;
  display: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img[src] {
  display: initial;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion.aa-cursor {
  background-color: #eee;
}
.algolia-autocomplete .aa-dropdown-menu .aa-suggestion em {
  font-weight: bold;
  font-style: normal;
}

</style>


<!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

<style type="text/css">

body {
  background-color: white;
}

.pandoc-table {
  width: 100%;
}

.pandoc-table>caption {
  margin-bottom: 10px;
}

.pandoc-table th:not([align]) {
  text-align: left;
}

.pagedtable-footer {
  font-size: 15px;
}

d-byline .byline {
  grid-template-columns: 2fr 2fr;
}

d-byline .byline h3 {
  margin-block-start: 1.5em;
}

d-byline .byline .authors-affiliations h3 {
  margin-block-start: 0.5em;
}

.authors-affiliations .orcid-id {
  width: 16px;
  height:16px;
  margin-left: 4px;
  margin-right: 4px;
  vertical-align: middle;
  padding-bottom: 2px;
}

d-title .dt-tags {
  margin-top: 1em;
  grid-column: text;
}

.dt-tags .dt-tag {
  text-decoration: none;
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0em 0.4em;
  margin-right: 0.5em;
  margin-bottom: 0.4em;
  font-size: 70%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

d-article table.gt_table td,
d-article table.gt_table th {
  border-bottom: none;
  font-size: 100%;
}

.html-widget {
  margin-bottom: 2.0em;
}

.l-screen-inset {
  padding-right: 16px;
}

.l-screen .caption {
  margin-left: 10px;
}

.shaded {
  background: rgb(247, 247, 247);
  padding-top: 20px;
  padding-bottom: 20px;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .html-widget {
  margin-bottom: 0;
  border: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .shaded-content {
  background: white;
}

.text-output {
  margin-top: 0;
  line-height: 1.5em;
}

.hidden {
  display: none !important;
}

d-article {
  padding-top: 2.5rem;
  padding-bottom: 30px;
}

d-appendix {
  padding-top: 30px;
}

d-article>p>img {
  width: 100%;
}

d-article h2 {
  margin: 1rem 0 1.5rem 0;
}

d-article h3 {
  margin-top: 1.5rem;
}

d-article iframe {
  border: 1px solid rgba(0, 0, 0, 0.1);
  margin-bottom: 2.0em;
  width: 100%;
}

/* Tweak code blocks */

d-article div.sourceCode code,
d-article pre code {
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
}

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: auto;
}

d-article div.sourceCode {
  background-color: white;
}

d-article div.sourceCode pre {
  padding-left: 10px;
  font-size: 12px;
  border-left: 2px solid rgba(0,0,0,0.1);
}

d-article pre {
  font-size: 12px;
  color: black;
  background: none;
  margin-top: 0;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

d-article pre a {
  border-bottom: none;
}

d-article pre a:hover {
  border-bottom: none;
  text-decoration: underline;
}

d-article details {
  grid-column: text;
  margin-bottom: 0.8em;
}

@media(min-width: 768px) {

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: visible !important;
}

d-article div.sourceCode pre {
  padding-left: 18px;
  font-size: 14px;
}

d-article pre {
  font-size: 14px;
}

}

figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

/* CSS for d-contents */

.d-contents {
  grid-column: text;
  color: rgba(0,0,0,0.8);
  font-size: 0.9em;
  padding-bottom: 1em;
  margin-bottom: 1em;
  padding-bottom: 0.5em;
  margin-bottom: 1em;
  padding-left: 0.25em;
  justify-self: start;
}

@media(min-width: 1000px) {
  .d-contents.d-contents-float {
    height: 0;
    grid-column-start: 1;
    grid-column-end: 4;
    justify-self: center;
    padding-right: 3em;
    padding-left: 2em;
  }
}

.d-contents nav h3 {
  font-size: 18px;
  margin-top: 0;
  margin-bottom: 1em;
}

.d-contents li {
  list-style-type: none
}

.d-contents nav > ul {
  padding-left: 0;
}

.d-contents ul {
  padding-left: 1em
}

.d-contents nav ul li {
  margin-top: 0.6em;
  margin-bottom: 0.2em;
}

.d-contents nav a {
  font-size: 13px;
  border-bottom: none;
  text-decoration: none
  color: rgba(0, 0, 0, 0.8);
}

.d-contents nav a:hover {
  text-decoration: underline solid rgba(0, 0, 0, 0.6)
}

.d-contents nav > ul > li > a {
  font-weight: 600;
}

.d-contents nav > ul > li > ul {
  font-weight: inherit;
}

.d-contents nav > ul > li > ul > li {
  margin-top: 0.2em;
}


.d-contents nav ul {
  margin-top: 0;
  margin-bottom: 0.25em;
}

.d-article-with-toc h2:nth-child(2) {
  margin-top: 0;
}


/* Figure */

.figure {
  position: relative;
  margin-bottom: 2.5em;
  margin-top: 1.5em;
}

.figure .caption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

.figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

.figure .caption a {
  color: rgba(0, 0, 0, 0.6);
}

.figure .caption b,
.figure .caption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}

/* Citations */

d-article .citation {
  color: inherit;
  cursor: inherit;
}

div.hanging-indent{
  margin-left: 1em; text-indent: -1em;
}

/* Citation hover box */

.tippy-box[data-theme~=light-border] {
  background-color: rgba(250, 250, 250, 0.95);
}

.tippy-content > p {
  margin-bottom: 0;
  padding: 2px;
}


/* Tweak 1000px media break to show more text */

@media(min-width: 1000px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }

  d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
  }
  figure .caption, .figure .caption, figure figcaption {
    font-size: 13px;
  }
}

@media(min-width: 1180px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 32px;
  }

  .grid {
    grid-column-gap: 32px;
  }
}


/* Get the citation styles for the appendix (not auto-injected on render since
   we do our own rendering of the citation appendix) */

d-appendix .citation-appendix,
.d-appendix .citation-appendix {
  font-size: 11px;
  line-height: 15px;
  border-left: 1px solid rgba(0, 0, 0, 0.1);
  padding-left: 18px;
  border: 1px solid rgba(0,0,0,0.1);
  background: rgba(0, 0, 0, 0.02);
  padding: 10px 18px;
  border-radius: 3px;
  color: rgba(150, 150, 150, 1);
  overflow: hidden;
  margin-top: -12px;
  white-space: pre-wrap;
  word-wrap: break-word;
}

/* Include appendix styles here so they can be overridden */

d-appendix {
  contain: layout style;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-top: 60px;
  margin-bottom: 0;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  color: rgba(0,0,0,0.5);
  padding-top: 60px;
  padding-bottom: 48px;
}

d-appendix h3 {
  grid-column: page-start / text-start;
  font-size: 15px;
  font-weight: 500;
  margin-top: 1em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.65);
}

d-appendix h3 + * {
  margin-top: 1em;
}

d-appendix ol {
  padding: 0 0 0 15px;
}

@media (min-width: 768px) {
  d-appendix ol {
    padding: 0 0 0 30px;
    margin-left: -30px;
  }
}

d-appendix li {
  margin-bottom: 1em;
}

d-appendix a {
  color: rgba(0, 0, 0, 0.6);
}

d-appendix > * {
  grid-column: text;
}

d-appendix > d-footnote-list,
d-appendix > d-citation-list,
d-appendix > distill-appendix {
  grid-column: screen;
}

/* Include footnote styles here so they can be overridden */

d-footnote-list {
  contain: layout style;
}

d-footnote-list > * {
  grid-column: text;
}

d-footnote-list a.footnote-backlink {
  color: rgba(0,0,0,0.3);
  padding-left: 0.5em;
}



/* Anchor.js */

.anchorjs-link {
  /*transition: all .25s linear; */
  text-decoration: none;
  border-bottom: none;
}
*:hover > .anchorjs-link {
  margin-left: -1.125em !important;
  text-decoration: none;
  border-bottom: none;
}

/* Social footer */

.social_footer {
  margin-top: 30px;
  margin-bottom: 0;
  color: rgba(0,0,0,0.67);
}

.disqus-comments {
  margin-right: 30px;
}

.disqus-comment-count {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  cursor: pointer;
}

#disqus_thread {
  margin-top: 30px;
}

.article-sharing a {
  border-bottom: none;
  margin-right: 8px;
}

.article-sharing a:hover {
  border-bottom: none;
}

.sidebar-section.subscribe {
  font-size: 12px;
  line-height: 1.6em;
}

.subscribe p {
  margin-bottom: 0.5em;
}


.article-footer .subscribe {
  font-size: 15px;
  margin-top: 45px;
}


.sidebar-section.custom {
  font-size: 12px;
  line-height: 1.6em;
}

.custom p {
  margin-bottom: 0.5em;
}

/* Styles for listing layout (hide title) */
.layout-listing d-title, .layout-listing .d-title {
  display: none;
}

/* Styles for posts lists (not auto-injected) */


.posts-with-sidebar {
  padding-left: 45px;
  padding-right: 45px;
}

.posts-list .description h2,
.posts-list .description p {
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
}

.posts-list .description h2 {
  font-weight: 700;
  border-bottom: none;
  padding-bottom: 0;
}

.posts-list h2.post-tag {
  border-bottom: 1px solid rgba(0, 0, 0, 0.2);
  padding-bottom: 12px;
}
.posts-list {
  margin-top: 60px;
  margin-bottom: 24px;
}

.posts-list .post-preview {
  text-decoration: none;
  overflow: hidden;
  display: block;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  padding: 24px 0;
}

.post-preview-last {
  border-bottom: none !important;
}

.posts-list .posts-list-caption {
  grid-column: screen;
  font-weight: 400;
}

.posts-list .post-preview h2 {
  margin: 0 0 6px 0;
  line-height: 1.2em;
  font-style: normal;
  font-size: 24px;
}

.posts-list .post-preview p {
  margin: 0 0 12px 0;
  line-height: 1.4em;
  font-size: 16px;
}

.posts-list .post-preview .thumbnail {
  box-sizing: border-box;
  margin-bottom: 24px;
  position: relative;
  max-width: 500px;
}
.posts-list .post-preview img {
  width: 100%;
  display: block;
}

.posts-list .metadata {
  font-size: 12px;
  line-height: 1.4em;
  margin-bottom: 18px;
}

.posts-list .metadata > * {
  display: inline-block;
}

.posts-list .metadata .publishedDate {
  margin-right: 2em;
}

.posts-list .metadata .dt-authors {
  display: block;
  margin-top: 0.3em;
  margin-right: 2em;
}

.posts-list .dt-tags {
  display: block;
  line-height: 1em;
}

.posts-list .dt-tags .dt-tag {
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0.3em 0.4em;
  margin-right: 0.2em;
  margin-bottom: 0.4em;
  font-size: 60%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

.posts-list img {
  opacity: 1;
}

.posts-list img[data-src] {
  opacity: 0;
}

.posts-more {
  clear: both;
}


.posts-sidebar {
  font-size: 16px;
}

.posts-sidebar h3 {
  font-size: 16px;
  margin-top: 0;
  margin-bottom: 0.5em;
  font-weight: 400;
  text-transform: uppercase;
}

.sidebar-section {
  margin-bottom: 30px;
}

.categories ul {
  list-style-type: none;
  margin: 0;
  padding: 0;
}

.categories li {
  color: rgba(0, 0, 0, 0.8);
  margin-bottom: 0;
}

.categories li>a {
  border-bottom: none;
}

.categories li>a:hover {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
}

.categories .active {
  font-weight: 600;
}

.categories .category-count {
  color: rgba(0, 0, 0, 0.4);
}


@media(min-width: 768px) {
  .posts-list .post-preview h2 {
    font-size: 26px;
  }
  .posts-list .post-preview .thumbnail {
    float: right;
    width: 30%;
    margin-bottom: 0;
  }
  .posts-list .post-preview .description {
    float: left;
    width: 45%;
  }
  .posts-list .post-preview .metadata {
    float: left;
    width: 20%;
    margin-top: 8px;
  }
  .posts-list .post-preview p {
    margin: 0 0 12px 0;
    line-height: 1.5em;
    font-size: 16px;
  }
  .posts-with-sidebar .posts-list {
    float: left;
    width: 75%;
  }
  .posts-with-sidebar .posts-sidebar {
    float: right;
    width: 20%;
    margin-top: 60px;
    padding-top: 24px;
    padding-bottom: 24px;
  }
}


/* Improve display for browsers without grid (IE/Edge <= 15) */

.downlevel {
  line-height: 1.6em;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  margin: 0;
}

.downlevel .d-title {
  padding-top: 6rem;
  padding-bottom: 1.5rem;
}

.downlevel .d-title h1 {
  font-size: 50px;
  font-weight: 700;
  line-height: 1.1em;
  margin: 0 0 0.5rem;
}

.downlevel .d-title p {
  font-weight: 300;
  font-size: 1.2rem;
  line-height: 1.55em;
  margin-top: 0;
}

.downlevel .d-byline {
  padding-top: 0.8em;
  padding-bottom: 0.8em;
  font-size: 0.8rem;
  line-height: 1.8em;
}

.downlevel .section-separator {
  border: none;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
}

.downlevel .d-article {
  font-size: 1.06rem;
  line-height: 1.7em;
  padding-top: 1rem;
  padding-bottom: 2rem;
}


.downlevel .d-appendix {
  padding-left: 0;
  padding-right: 0;
  max-width: none;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.5);
  padding-top: 40px;
  padding-bottom: 48px;
}

.downlevel .footnotes ol {
  padding-left: 13px;
}

.downlevel .base-grid,
.downlevel .distill-header,
.downlevel .d-title,
.downlevel .d-abstract,
.downlevel .d-article,
.downlevel .d-appendix,
.downlevel .distill-appendix,
.downlevel .d-byline,
.downlevel .d-footnote-list,
.downlevel .d-citation-list,
.downlevel .distill-footer,
.downlevel .appendix-bottom,
.downlevel .posts-container {
  padding-left: 40px;
  padding-right: 40px;
}

@media(min-width: 768px) {
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
  padding-left: 150px;
  padding-right: 150px;
  max-width: 900px;
}
}

.downlevel pre code {
  display: block;
  border-left: 2px solid rgba(0, 0, 0, .1);
  padding: 0 0 0 20px;
  font-size: 14px;
}

.downlevel code, .downlevel pre {
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

.downlevel .posts-list .post-preview {
  color: inherit;
}



</style>

<script type="application/javascript">

function is_downlevel_browser() {
  if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                 window.navigator.userAgent)) {
    return true;
  } else {
    return window.load_distill_framework === undefined;
  }
}

// show body when load is complete
function on_load_complete() {

  // add anchors
  if (window.anchors) {
    window.anchors.options.placement = 'left';
    window.anchors.add('d-article > h2, d-article > h3, d-article > h4, d-article > h5');
  }


  // set body to visible
  document.body.style.visibility = 'visible';

  // force redraw for leaflet widgets
  if (window.HTMLWidgets) {
    var maps = window.HTMLWidgets.findAll(".leaflet");
    $.each(maps, function(i, el) {
      var map = this.getMap();
      map.invalidateSize();
      map.eachLayer(function(layer) {
        if (layer instanceof L.TileLayer)
          layer.redraw();
      });
    });
  }

  // trigger 'shown' so htmlwidgets resize
  $('d-article').trigger('shown');
}

function init_distill() {

  init_common();

  // create front matter
  var front_matter = $('<d-front-matter></d-front-matter>');
  $('#distill-front-matter').wrap(front_matter);

  // create d-title
  $('.d-title').changeElementType('d-title');

  // create d-byline
  var byline = $('<d-byline></d-byline>');
  $('.d-byline').replaceWith(byline);

  // create d-article
  var article = $('<d-article></d-article>');
  $('.d-article').wrap(article).children().unwrap();

  // move posts container into article
  $('.posts-container').appendTo($('d-article'));

  // create d-appendix
  $('.d-appendix').changeElementType('d-appendix');

  // flag indicating that we have appendix items
  var appendix = $('.appendix-bottom').children('h3').length > 0;

  // replace footnotes with <d-footnote>
  $('.footnote-ref').each(function(i, val) {
    appendix = true;
    var href = $(this).attr('href');
    var id = href.replace('#', '');
    var fn = $('#' + id);
    var fn_p = $('#' + id + '>p');
    fn_p.find('.footnote-back').remove();
    var text = fn_p.html();
    var dtfn = $('<d-footnote></d-footnote>');
    dtfn.html(text);
    $(this).replaceWith(dtfn);
  });
  // remove footnotes
  $('.footnotes').remove();

  // move refs into #references-listing
  $('#references-listing').replaceWith($('#refs'));

  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    var id = $(this).attr('id');
    $('.d-contents a[href="#' + id + '"]').parent().remove();
    appendix = true;
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
  });

  // show d-appendix if we have appendix content
  $("d-appendix").css('display', appendix ? 'grid' : 'none');

  // localize layout chunks to just output
  $('.layout-chunk').each(function(i, val) {

    // capture layout
    var layout = $(this).attr('data-layout');

    // apply layout to markdown level block elements
    var elements = $(this).children().not('details, div.sourceCode, pre, script');
    elements.each(function(i, el) {
      var layout_div = $('<div class="' + layout + '"></div>');
      if (layout_div.hasClass('shaded')) {
        var shaded_content = $('<div class="shaded-content"></div>');
        $(this).wrap(shaded_content);
        $(this).parent().wrap(layout_div);
      } else {
        $(this).wrap(layout_div);
      }
    });


    // unwrap the layout-chunk div
    $(this).children().unwrap();
  });

  // remove code block used to force  highlighting css
  $('.distill-force-highlighting-css').parent().remove();

  // remove empty line numbers inserted by pandoc when using a
  // custom syntax highlighting theme
  $('code.sourceCode a:empty').remove();

  // load distill framework
  load_distill_framework();

  // wait for window.distillRunlevel == 4 to do post processing
  function distill_post_process() {

    if (!window.distillRunlevel || window.distillRunlevel < 4)
      return;

    // hide author/affiliations entirely if we have no authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
    if (!have_authors)
      $('d-byline').addClass('hidden');

    // article with toc class
    $('.d-contents').parent().addClass('d-article-with-toc');

    // strip links that point to #
    $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

    // add orcid ids
    $('.authors-affiliations').find('.author').each(function(i, el) {
      var orcid_id = front_matter.authors[i].orcidID;
      if (orcid_id) {
        var a = $('<a></a>');
        a.attr('href', 'https://orcid.org/' + orcid_id);
        var img = $('<img></img>');
        img.addClass('orcid-id');
        img.attr('alt', 'ORCID ID');
        img.attr('src','data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==');
        a.append(img);
        $(this).append(a);
      }
    });

    // hide elements of author/affiliations grid that have no value
    function hide_byline_column(caption) {
      $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
    }

    // affiliations
    var have_affiliations = false;
    for (var i = 0; i<front_matter.authors.length; ++i) {
      var author = front_matter.authors[i];
      if (author.affiliation !== "&nbsp;") {
        have_affiliations = true;
        break;
      }
    }
    if (!have_affiliations)
      $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

    // published date
    if (!front_matter.publishedDate)
      hide_byline_column("Published");

    // document object identifier
    var doi = $('d-byline').find('h3:contains("DOI")');
    var doi_p = doi.next().empty();
    if (!front_matter.doi) {
      // if we have a citation and valid citationText then link to that
      if ($('#citation').length > 0 && front_matter.citationText) {
        doi.html('Citation');
        $('<a href="#citation"></a>')
          .text(front_matter.citationText)
          .appendTo(doi_p);
      } else {
        hide_byline_column("DOI");
      }
    } else {
      $('<a></a>')
         .attr('href', "https://doi.org/" + front_matter.doi)
         .html(front_matter.doi)
         .appendTo(doi_p);
    }

     // change plural form of authors/affiliations
    if (front_matter.authors.length === 1) {
      var grid = $('.authors-affiliations');
      grid.children('h3:contains("Authors")').text('Author');
      grid.children('h3:contains("Affiliations")').text('Affiliation');
    }

    // remove d-appendix and d-footnote-list local styles
    $('d-appendix > style:first-child').remove();
    $('d-footnote-list > style:first-child').remove();

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // hoverable references
    $('span.citation[data-cites]').each(function() {
      const citeChild = $(this).children()[0]
      // Do not process if @xyz has been used without escaping and without bibliography activated
      // https://github.com/rstudio/distill/issues/466
      if (citeChild === undefined) return true

      if (citeChild.nodeName == "D-FOOTNOTE") {
        var fn = citeChild
        $(this).html(fn.shadowRoot.querySelector("sup"))
        $(this).id = fn.id
        fn.remove()
      }
      var refs = $(this).attr('data-cites').split(" ");
      var refHtml = refs.map(function(ref) {
        // Could use CSS.escape too here, we insure backward compatibility in navigator
        return "<p>" + $('div[id="ref-' + ref + '"]').html() + "</p>";
      }).join("\n");
      window.tippy(this, {
        allowHTML: true,
        content: refHtml,
        maxWidth: 500,
        interactive: true,
        interactiveBorder: 10,
        theme: 'light-border',
        placement: 'bottom-start'
      });
    });

    // fix footnotes in tables (#411)
    // replacing broken distill.pub feature
    $('table d-footnote').each(function() {
      // we replace internal showAtNode methode which is triggered when hovering a footnote
      this.hoverBox.showAtNode = function(node) {
        // ported from https://github.com/distillpub/template/pull/105/files
        calcOffset = function(elem) {
            let x = elem.offsetLeft;
            let y = elem.offsetTop;
            // Traverse upwards until an `absolute` element is found or `elem`
            // becomes null.
            while (elem = elem.offsetParent && elem.style.position != 'absolute') {
                x += elem.offsetLeft;
                y += elem.offsetTop;
            }

            return { left: x, top: y };
        }
        // https://developer.mozilla.org/en-US/docs/Web/API/HTMLElement/offsetTop
        const bbox = node.getBoundingClientRect();
        const offset = calcOffset(node);
        this.show([offset.left + bbox.width, offset.top + bbox.height]);
      }
    })

    // clear polling timer
    clearInterval(tid);

    // show body now that everything is ready
    on_load_complete();
  }

  var tid = setInterval(distill_post_process, 50);
  distill_post_process();

}

function init_downlevel() {

  init_common();

   // insert hr after d-title
  $('.d-title').after($('<hr class="section-separator"/>'));

  // check if we have authors
  var front_matter = JSON.parse($("#distill-front-matter").html());
  var have_authors = front_matter.authors && front_matter.authors.length > 0;

  // manage byline/border
  if (!have_authors)
    $('.d-byline').remove();
  $('.d-byline').after($('<hr class="section-separator"/>'));
  $('.d-byline a').remove();

  // remove toc
  $('.d-contents').remove();

  // move appendix elements
  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
  });


  // inject headers into references and footnotes
  var refs_header = $('<h3></h3>');
  refs_header.text('References');
  $('#refs').prepend(refs_header);

  var footnotes_header = $('<h3></h3');
  footnotes_header.text('Footnotes');
  $('.footnotes').children('hr').first().replaceWith(footnotes_header);

  // move appendix-bottom entries to the bottom
  $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
  $('.appendix-bottom').remove();

  // remove appendix if it's empty
  if ($('.d-appendix').children().length === 0)
    $('.d-appendix').remove();

  // prepend separator above appendix
  $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

  // trim code
  $('pre>code').each(function(i, val) {
    $(this).html($.trim($(this).html()));
  });

  // move posts-container right before article
  $('.posts-container').insertBefore($('.d-article'));

  $('body').addClass('downlevel');

  on_load_complete();
}


function init_common() {

  // jquery plugin to change element types
  (function($) {
    $.fn.changeElementType = function(newType) {
      var attrs = {};

      $.each(this[0].attributes, function(idx, attr) {
        attrs[attr.nodeName] = attr.nodeValue;
      });

      this.replaceWith(function() {
        return $("<" + newType + "/>", attrs).append($(this).contents());
      });
    };
  })(jQuery);

  // prevent underline for linked images
  $('a > img').parent().css({'border-bottom' : 'none'});

  // mark non-body figures created by knitr chunks as 100% width
  $('.layout-chunk').each(function(i, val) {
    var figures = $(this).find('img, .html-widget');
    // ignore leaflet img layers (#106)
    figures = figures.filter(':not(img[class*="leaflet"])')
    if ($(this).attr('data-layout') !== "l-body") {
      figures.css('width', '100%');
    } else {
      figures.css('max-width', '100%');
      figures.filter("[width]").each(function(i, val) {
        var fig = $(this);
        fig.css('width', fig.attr('width') + 'px');
      });

    }
  });

  // auto-append index.html to post-preview links in file: protocol
  // and in rstudio ide preview
  $('.post-preview').each(function(i, val) {
    if (window.location.protocol === "file:")
      $(this).attr('href', $(this).attr('href') + "index.html");
  });

  // get rid of index.html references in header
  if (window.location.protocol !== "file:") {
    $('.distill-site-header a[href]').each(function(i,val) {
      $(this).attr('href', $(this).attr('href').replace(/^index[.]html/, "./"));
    });
  }

  // add class to pandoc style tables
  $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
  $('.kable-table').children('table').addClass('pandoc-table');

  // add figcaption style to table captions
  $('caption').parent('table').addClass("figcaption");

  // initialize posts list
  if (window.init_posts_list)
    window.init_posts_list();

  // implmement disqus comment link
  $('.disqus-comment-count').click(function() {
    window.headroom_prevent_pin = true;
    $('#disqus_thread').toggleClass('hidden');
    if (!$('#disqus_thread').hasClass('hidden')) {
      var offset = $(this).offset();
      $(window).resize();
      $('html, body').animate({
        scrollTop: offset.top - 35
      });
    }
  });
}

document.addEventListener('DOMContentLoaded', function() {
  if (is_downlevel_browser())
    init_downlevel();
  else
    window.addEventListener('WebComponentsReady', init_distill);
});

</script>

<!--/radix_placeholder_distill-->
  <script src="../../site_libs/header-attrs-2.13/header-attrs.js"></script>
  <script src="../../site_libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
  <script src="../../site_libs/viz-1.8.2/viz.js"></script>
  <link href="../../site_libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
  <script src="../../site_libs/grViz-binding-1.0.9/grViz.js"></script>
  <script src="../../site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
  <script src="../../site_libs/popper-2.6.0/popper.min.js"></script>
  <link href="../../site_libs/tippy-6.2.7/tippy.css" rel="stylesheet" />
  <link href="../../site_libs/tippy-6.2.7/tippy-light-border.css" rel="stylesheet" />
  <script src="../../site_libs/tippy-6.2.7/tippy.umd.min.js"></script>
  <script src="../../site_libs/anchor-4.2.2/anchor.min.js"></script>
  <script src="../../site_libs/bowser-1.9.3/bowser.min.js"></script>
  <script src="../../site_libs/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="../../site_libs/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
<!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"ML Homework 2","description":"A short description of the post.","authors":[{"author":"Noah Milstein","authorURL":{},"affiliation":"&nbsp;","affiliationURL":"#","orcidID":""}],"publishedDate":"2022-03-29T00:00:00.000-04:00","citationText":"Milstein, 2022"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<header class="header header--fixed" role="banner">
<nav class="distill-site-nav distill-site-header">
<div class="nav-left">
<a href="../../index.html" class="title">Noah Milstein DACSS Blog</a>
<input id="distill-search" class="nav-search hidden" type="text" placeholder="Search..."/>
</div>
<div class="nav-right">
<a href="../../index.html">Home</a>
<a href="../../about.html">About</a>
<a href="javascript:void(0);" class="nav-toggle">&#9776;</a>
</div>
</nav>
</header>
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>ML Homework 2</h1>
<!--radix_placeholder_categories-->
<!--/radix_placeholder_categories-->
<p><p>A short description of the post.</p></p>
</div>

<div class="d-byline">
  Noah Milstein true 
  
<br/>2022-03-29
</div>

<div class="d-article">
<div class="layout-chunk" data-layout="l-body">

</div>
<h3 id="ch.-4-exercise-16">Ch. 4, Exercise 16</h3>
<p><strong>Question:</strong> Using the Boston data set, fit
classification models in order to predict whether a given census tract
has a crime rate above or below the median. Explore logistic regression,
LDA, naive Bayes, and KNN models using various subsets of the
predictors. Describe your findings.</p>
<h4 id="looking-at-the-boston-data">Looking at the Boston Data</h4>
<h5 id="data-exploration-and-revue-of-homework-1">Data Exploration and
Revue of Homework 1</h5>
<p><strong>Answer:</strong> In homework 1 we looked at predictors for
linear regression individual and with all in the same equation however
we did not look at logistic regression. As can be seen from the
correlation graph above and prior correlation calculations a handful of
predictors seem to exhibit some correlation with crime that I will be
using, these will be rad, tax dis medv, and lstat.</p>
<p>Here we want to predict if crime is above the median so first we will
make a variable that reflects this.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>median_crime_rate</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/median.html'>median</a></span><span class='op'>(</span><span class='va'>Boston</span><span class='op'>$</span><span class='va'>crim</span><span class='op'>)</span>

<span class='va'>median_crime_rate</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.25651</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Answer Median Crime:</strong> In order to create the median
crime rate dummy variable I calculate the median crime rate in the
Boston dataset and use the mutate function to create a new column with
this data.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>Boston_over_median</span> <span class='op'>&lt;-</span> <span class='va'>Boston</span> <span class='op'>%&gt;%</span> <span class='fu'>mutate</span><span class='op'>(</span>median_crime_in_tract <span class='op'>=</span> <span class='fu'>case_when</span><span class='op'>(</span>
  <span class='va'>crim</span> <span class='op'>&lt;</span> <span class='fl'>0.25651</span> <span class='op'>~</span> <span class='fl'>0</span>,
    <span class='va'>crim</span> <span class='op'>&gt;=</span> <span class='fl'>0.25651</span> <span class='op'>~</span> <span class='fl'>1</span><span class='op'>)</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p><strong>Answer Pairs</strong> After this I look at pair to attempt to
distinguish if some variables seem particularly correlated with median
crime rate visually.</p>
<div class="layout-chunk" data-layout="l-body">
<p><img src="ml-homework-2_files/figure-html5/unnamed-chunk-4-1.png" width="624" /></p>
</div>
<p><strong>Building a training and test set:</strong> Though it is
mentioned more in later chapters the authors do use a split in their
data in Smarket to act as their training. In this case I will do
something similar, however, I will use a sample of 70% of the data.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>222</span><span class='op'>)</span>

<span class='va'>in_training</span><span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/sample.html'>sample</a></span><span class='op'>(</span><span class='fl'>1</span><span class='op'>:</span><span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>Boston_over_median</span><span class='op'>)</span>,  <span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>Boston</span><span class='op'>)</span> <span class='op'>*</span> <span class='fl'>0.7</span> <span class='op'>)</span>

<span class='va'>training_boston</span> <span class='op'>&lt;-</span> <span class='va'>Boston_over_median</span><span class='op'>[</span><span class='va'>in_training</span>,<span class='op'>]</span>

<span class='va'>test_boston</span> <span class='op'>&lt;-</span> <span class='va'>Boston_over_median</span><span class='op'>[</span><span class='op'>-</span><span class='va'>in_training</span>,<span class='op'>]</span>
</code></pre>
</div>
</div>
<p><strong>Model Choice Logistic 1:</strong> Firstly I will be using all
of the variables in my logistic regression and using both p-values and
standard errors along with the predict function to evaluate the
model</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>222</span><span class='op'>)</span>

<span class='va'>logsitic_Boston_1</span><span class='op'>&lt;-</span>  <span class='fu'><a href='https://rdrr.io/r/stats/glm.html'>glm</a></span><span class='op'>(</span><span class='va'>median_crime_in_tract</span> <span class='op'>~</span> <span class='va'>zn</span> <span class='op'>+</span> <span class='va'>indus</span> <span class='op'>+</span> <span class='va'>chas</span> <span class='op'>+</span> <span class='va'>nox</span> <span class='op'>+</span> <span class='va'>rm</span> <span class='op'>+</span> <span class='va'>age</span> <span class='op'>+</span> <span class='va'>dis</span> <span class='op'>+</span> <span class='va'>rad</span> <span class='op'>+</span> <span class='va'>tax</span> <span class='op'>+</span> <span class='va'>ptratio</span> <span class='op'>+</span> <span class='va'>lstat</span> <span class='op'>+</span> <span class='va'>medv</span>, data <span class='op'>=</span> <span class='va'>Boston_over_median</span>, family <span class='op'>=</span> <span class='va'>binomial</span>, subset<span class='op'>=</span><span class='va'>in_training</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/base/summary.html'>summary</a></span><span class='op'>(</span><span class='va'>logsitic_Boston_1</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>
Call:
glm(formula = median_crime_in_tract ~ zn + indus + chas + nox + 
    rm + age + dis + rad + tax + ptratio + lstat + medv, family = binomial, 
    data = Boston_over_median, subset = in_training)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.0510  -0.1337  -0.0003   0.0035   3.4664  

Coefficients:
              Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -48.641048   7.865389  -6.184 6.24e-10 ***
zn           -0.092755   0.042744  -2.170  0.03000 *  
indus        -0.074307   0.050366  -1.475  0.14012    
chas          0.468421   0.798887   0.586  0.55765    
nox          51.914808   9.097957   5.706 1.16e-08 ***
rm            0.444596   0.867999   0.512  0.60851    
age           0.014141   0.013691   1.033  0.30167    
dis           0.784864   0.256550   3.059  0.00222 ** 
rad           0.631667   0.196382   3.217  0.00130 ** 
tax          -0.005575   0.003062  -1.821  0.06861 .  
ptratio       0.442991   0.153263   2.890  0.00385 ** 
lstat         0.141092   0.058371   2.417  0.01564 *  
medv          0.166757   0.086194   1.935  0.05303 .  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 490.75  on 353  degrees of freedom
Residual deviance: 146.76  on 341  degrees of freedom
AIC: 172.76

Number of Fisher Scoring iterations: 9</code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>222</span><span class='op'>)</span>

<span class='va'>logsitic_1_Boston_probs</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>logsitic_Boston_1</span>, <span class='va'>test_boston</span>,
type <span class='op'>=</span> <span class='st'>"response"</span><span class='op'>)</span>

<span class='va'>log_preds_1</span><span class='op'>&lt;-</span><span class='fu'><a href='https://rdrr.io/r/base/ifelse.html'>ifelse</a></span><span class='op'>(</span><span class='va'>logsitic_1_Boston_probs</span> <span class='op'>&gt;=</span> <span class='fl'>0.5</span>, <span class='fl'>1</span>, <span class='fl'>0</span><span class='op'>)</span>

<span class='va'>prediction_1_logs</span> <span class='op'>&lt;-</span><span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='va'>log_preds_1</span> <span class='op'>==</span> <span class='va'>test_boston</span><span class='op'>$</span><span class='va'>median_crime_in_tract</span><span class='op'>)</span>

<span class='va'>prediction_1_logs</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.8618421</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Results Logistic 1:</strong> As can be seen above the first
logistic model appears to correctly evaluate whether or not a census
tract in our test set is above or below the median correctly 0.8618421
or 86.2% of the time.</p>
<p><strong>Model Choice Logistic 2:</strong> For my second function I
will be using only the variables that my glm output as statistically
significant based on the glm p-values. This would suggests that most of
these coefficients are unlikely to be zero.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>222</span><span class='op'>)</span>

<span class='va'>logsitic_Boston_2</span> <span class='op'>&lt;-</span>  <span class='fu'><a href='https://rdrr.io/r/stats/glm.html'>glm</a></span><span class='op'>(</span><span class='va'>median_crime_in_tract</span> <span class='op'>~</span> <span class='va'>zn</span> <span class='op'>+</span> <span class='va'>nox</span> <span class='op'>+</span> <span class='va'>dis</span> <span class='op'>+</span> <span class='va'>rad</span> <span class='op'>+</span> 
                            
<span class='va'>ptratio</span> <span class='op'>+</span> <span class='va'>medv</span> , data <span class='op'>=</span> <span class='va'>Boston_over_median</span>, family <span class='op'>=</span> <span class='va'>binomial</span>, 

subset<span class='op'>=</span><span class='va'>in_training</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/base/summary.html'>summary</a></span><span class='op'>(</span><span class='va'>logsitic_Boston_2</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>
Call:
glm(formula = median_crime_in_tract ~ zn + nox + dis + rad + 
    ptratio + medv, family = binomial, data = Boston_over_median, 
    subset = in_training)

Deviance Residuals: 
     Min        1Q    Median        3Q       Max  
-2.07337  -0.24571  -0.00187   0.00753   3.13797  

Coefficients:
             Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -35.02931    5.78928  -6.051 1.44e-09 ***
zn           -0.07337    0.03319  -2.210 0.027089 *  
nox          41.29154    6.64906   6.210 5.29e-10 ***
dis           0.60332    0.21526   2.803 0.005068 ** 
rad           0.48104    0.13704   3.510 0.000448 ***
ptratio       0.32090    0.12317   2.605 0.009175 ** 
medv          0.11077    0.03732   2.968 0.002993 ** 
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 490.75  on 353  degrees of freedom
Residual deviance: 168.50  on 347  degrees of freedom
AIC: 182.5

Number of Fisher Scoring iterations: 8</code></pre>
</div>
<p><strong>Results Logistic 2:</strong> As can be seen above this has
lead to a very slightly reduction in the error rate from about 86% to
about 89% of tracts being correctly identified.</p>
<p><strong>Model Choice Logistic 3:</strong> Next, I will remove
variables that changed in their significance, I will remove ones that
went down in significance in my third iteration and include those that
stayed the same or improved in their statistical significance so here
we just remove zn.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>727</span><span class='op'>)</span>

<span class='va'>logsitic_Boston_3</span> <span class='op'>&lt;-</span>  <span class='fu'><a href='https://rdrr.io/r/stats/glm.html'>glm</a></span><span class='op'>(</span><span class='va'>median_crime_in_tract</span> <span class='op'>~</span> <span class='va'>nox</span> <span class='op'>+</span> <span class='va'>dis</span> <span class='op'>+</span> <span class='va'>rad</span> <span class='op'>+</span> 
                            
<span class='va'>medv</span> , data <span class='op'>=</span> <span class='va'>Boston_over_median</span>, family <span class='op'>=</span> <span class='va'>binomial</span>, subset<span class='op'>=</span><span class='va'>in_training</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/base/summary.html'>summary</a></span><span class='op'>(</span><span class='va'>logsitic_Boston_3</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>
Call:
glm(formula = median_crime_in_tract ~ nox + dis + rad + medv, 
    family = binomial, data = Boston_over_median, subset = in_training)

Deviance Residuals: 
     Min        1Q    Median        3Q       Max  
-1.96251  -0.34660  -0.03326   0.01130   2.61492  

Coefficients:
             Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -23.82357    4.00139  -5.954 2.62e-09 ***
nox          36.77822    6.01008   6.119 9.39e-10 ***
dis           0.30796    0.16164   1.905 0.056747 .  
rad           0.43698    0.12121   3.605 0.000312 ***
medv          0.03308    0.02884   1.147 0.251420    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 490.75  on 353  degrees of freedom
Residual deviance: 187.91  on 349  degrees of freedom
AIC: 197.91

Number of Fisher Scoring iterations: 8</code></pre>
</div>
<p><strong>Results Logistic 3:</strong> As can be seen by the error rate
above, removing the single variable did not serve to improve the fit as
it is still guessed about 89% of the tracts correctly.</p>
<p><strong>Model Choice LDA 1:</strong> My first fit for LDA will again
start by using all of the variables in the dataset.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>292</span><span class='op'>)</span>

<span class='va'>lda.fit_1</span> <span class='op'>&lt;-</span> <span class='fu'>lda</span><span class='op'>(</span><span class='va'>median_crime_in_tract</span> <span class='op'>~</span> <span class='va'>zn</span> <span class='op'>+</span> <span class='va'>indus</span> <span class='op'>+</span> <span class='va'>chas</span> <span class='op'>+</span> <span class='va'>nox</span> <span class='op'>+</span> <span class='va'>rm</span> <span class='op'>+</span> 
<span class='va'>age</span> <span class='op'>+</span> <span class='va'>dis</span> <span class='op'>+</span> <span class='va'>rad</span> <span class='op'>+</span> <span class='va'>tax</span> <span class='op'>+</span> <span class='va'>ptratio</span> <span class='op'>+</span> <span class='va'>lstat</span> <span class='op'>+</span> <span class='va'>medv</span>, 
data <span class='op'>=</span> <span class='va'>Boston_over_median</span>, subset<span class='op'>=</span><span class='va'>in_training</span><span class='op'>)</span>

<span class='va'>lda.fit_1</span>
</code></pre>
</div>
<pre><code>Call:
lda(median_crime_in_tract ~ zn + indus + chas + nox + rm + age + 
    dis + rad + tax + ptratio + lstat + medv, data = Boston_over_median, 
    subset = in_training)

Prior probabilities of groups:
  0   1 
0.5 0.5 

Group means:
         zn     indus       chas       nox       rm      age      dis
0 23.161017  6.824407 0.06214689 0.4684520 6.407825 49.71808 5.085899
1  1.265537 15.204181 0.10169492 0.6392147 6.174492 86.04802 2.537347
       rad      tax  ptratio     lstat     medv
0  4.19209 307.8192 17.85706  9.061356 25.25424
1 13.92655 496.0226 18.95932 16.165819 20.23842

Coefficients of linear discriminants:
                  LD1
zn      -0.0075446955
indus    0.0111437527
chas    -0.2075615996
nox      9.1062150722
rm       0.2401656098
age      0.0131358309
dis      0.1330540845
rad      0.0584337654
tax     -0.0006712969
ptratio  0.1157332806
lstat    0.0409740539
medv     0.0509953338</code></pre>
</div>
<p><strong>Results LDA 1:</strong> As can be seen above the LDA output
suggests that pihat1 and pihat2 are both 0.5 so half of the tracts are
below and half are above the median as should be expected.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>292</span><span class='op'>)</span>

<span class='va'>lda.pred</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>lda.fit_1</span>, <span class='va'>test_boston</span><span class='op'>)</span>

<span class='va'>lda.class</span> <span class='op'>&lt;-</span> <span class='va'>lda.pred</span><span class='op'>$</span><span class='va'>class</span>

<span class='fu'><a href='https://rdrr.io/r/base/table.html'>table</a></span><span class='op'>(</span><span class='va'>lda.class</span>, <span class='va'>test_boston</span><span class='op'>$</span><span class='va'>median_crime_in_tract</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">0</th>
<th style="text-align: right;">1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">0</td>
<td style="text-align: right;">67</td>
<td style="text-align: right;">17</td>
</tr>
<tr class="even">
<td style="text-align: left;">1</td>
<td style="text-align: right;">9</td>
<td style="text-align: right;">59</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Results LDA 1 Continued:</strong> As can be seen above the
first LDA model with all of the predictors included predicts the test
median crime rate dummy variable correctly about 82.9% of the time, in
total it predicts the splits above correctly and the total percent as
indicated below.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='va'>lda.class</span> <span class='op'>==</span> <span class='va'>test_boston</span><span class='op'>$</span><span class='va'>median_crime_in_tract</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.8289474</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Results LDA 1 Continued:</strong> Below we see that with a
50% threshold we acquire the two predictions below.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/sum.html'>sum</a></span><span class='op'>(</span><span class='va'>lda.pred</span><span class='op'>$</span><span class='va'>posterior</span><span class='op'>[</span>, <span class='fl'>1</span><span class='op'>]</span> <span class='op'>&gt;=</span> <span class='fl'>.5</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">84</td>
</tr>
</tbody>
</table>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/sum.html'>sum</a></span><span class='op'>(</span><span class='va'>lda.pred</span><span class='op'>$</span><span class='va'>posterior</span><span class='op'>[</span>, <span class='fl'>1</span><span class='op'>]</span> <span class='op'>&lt;</span> <span class='fl'>.5</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">68</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Results LDA 1 Continued:</strong> The plot of the fit is as
plotted below.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='va'>lda.fit_1</span><span class='op'>)</span>
</code></pre>
</div>
<p><img src="ml-homework-2_files/figure-html5/unnamed-chunk-16-1.png" width="624" /></p>
</div>
<p><strong>Model Choice LDA 2:</strong> Since LDA does not give an
indication of the performance of individual predictors I will model my
second one using the predictors that logistic regression indicated as
statistically significant, or likely to be non-zero.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>292</span><span class='op'>)</span>

<span class='va'>lda.fit_2</span> <span class='op'>&lt;-</span> <span class='fu'>lda</span><span class='op'>(</span><span class='va'>median_crime_in_tract</span> <span class='op'>~</span>  <span class='va'>zn</span> <span class='op'>+</span> <span class='va'>nox</span> <span class='op'>+</span> <span class='va'>dis</span> <span class='op'>+</span> <span class='va'>rad</span> <span class='op'>+</span> <span class='va'>ptratio</span> 
                 <span class='op'>+</span> <span class='va'>medv</span> , data <span class='op'>=</span> <span class='va'>Boston_over_median</span>, subset<span class='op'>=</span><span class='va'>in_training</span><span class='op'>)</span>

<span class='va'>lda.fit_2</span> 
</code></pre>
</div>
<pre><code>Call:
lda(median_crime_in_tract ~ zn + nox + dis + rad + ptratio + 
    medv, data = Boston_over_median, subset = in_training)

Prior probabilities of groups:
  0   1 
0.5 0.5 

Group means:
         zn       nox      dis      rad  ptratio     medv
0 23.161017 0.4684520 5.085899  4.19209 17.85706 25.25424
1  1.265537 0.6392147 2.537347 13.92655 18.95932 20.23842

Coefficients of linear discriminants:
                 LD1
zn      -0.007133417
nox     10.155028179
dis     -0.006666860
rad      0.051446121
ptratio  0.116810250
medv     0.036270047</code></pre>
</div>
<p><strong>Results LDA 2:</strong> As can be seen above the LDA output
suggests that pihat1 and pihat2 are both 0.5 so half of the tracts are
below and half are above the median as should be expected as in the
first example.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>292</span><span class='op'>)</span>

<span class='va'>lda.pred_2</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>lda.fit_2</span>, <span class='va'>test_boston</span><span class='op'>)</span>

<span class='va'>lda_2.class</span> <span class='op'>&lt;-</span> <span class='va'>lda.pred_2</span><span class='op'>$</span><span class='va'>class</span>

<span class='fu'><a href='https://rdrr.io/r/base/table.html'>table</a></span><span class='op'>(</span><span class='va'>lda_2.class</span>, <span class='va'>test_boston</span><span class='op'>$</span><span class='va'>median_crime_in_tract</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">0</th>
<th style="text-align: right;">1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">0</td>
<td style="text-align: right;">65</td>
<td style="text-align: right;">15</td>
</tr>
<tr class="even">
<td style="text-align: left;">1</td>
<td style="text-align: right;">11</td>
<td style="text-align: right;">61</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Results LDA 2 continued:</strong> As can be seen below this
LDA performs incredibly similarly to the first 0.8289474 with both
having identical correct classification rates.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='va'>lda_2.class</span> <span class='op'>==</span> <span class='va'>test_boston</span><span class='op'>$</span><span class='va'>median_crime_in_tract</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.8289474</td>
</tr>
</tbody>
</table>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/sum.html'>sum</a></span><span class='op'>(</span><span class='va'>lda.pred_2</span><span class='op'>$</span><span class='va'>posterior</span><span class='op'>[</span>, <span class='fl'>1</span><span class='op'>]</span> <span class='op'>&gt;=</span> <span class='fl'>.5</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">80</td>
</tr>
</tbody>
</table>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/sum.html'>sum</a></span><span class='op'>(</span><span class='va'>lda.pred_2</span><span class='op'>$</span><span class='va'>posterior</span><span class='op'>[</span>, <span class='fl'>1</span><span class='op'>]</span> <span class='op'>&lt;</span> <span class='fl'>.5</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">72</td>
</tr>
</tbody>
</table>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='va'>lda.fit_2</span><span class='op'>)</span>
</code></pre>
</div>
<p><img src="ml-homework-2_files/figure-html5/unnamed-chunk-21-1.png" width="624" /></p>
</div>
<p><strong>Model Choice LDA 3:</strong> For my third LDA model choice I
used all of the dummy variables and nox to see how using a number of
categorical variables effects the outcome of LDA.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>7209</span><span class='op'>)</span>

<span class='va'>lda.fit_3</span><span class='op'>&lt;-</span> <span class='fu'>lda</span><span class='op'>(</span><span class='va'>median_crime_in_tract</span> <span class='op'>~</span> <span class='va'>age</span> <span class='op'>+</span> <span class='va'>rad</span> <span class='op'>+</span> <span class='va'>chas</span>
 <span class='op'>+</span> <span class='va'>nox</span> , data <span class='op'>=</span> <span class='va'>Boston_over_median</span>, subset<span class='op'>=</span><span class='va'>in_training</span><span class='op'>)</span>

<span class='va'>lda.fit_3</span>
</code></pre>
</div>
<pre><code>Call:
lda(median_crime_in_tract ~ age + rad + chas + nox, data = Boston_over_median, 
    subset = in_training)

Prior probabilities of groups:
  0   1 
0.5 0.5 

Group means:
       age      rad       chas       nox
0 49.71808  4.19209 0.06214689 0.4684520
1 86.04802 13.92655 0.10169492 0.6392147

Coefficients of linear discriminants:
            LD1
age  0.01539699
rad  0.06022015
chas 0.01643176
nox  6.98239859</code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>7209</span><span class='op'>)</span>

<span class='va'>lda.pred_3</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>lda.fit_3</span>, <span class='va'>test_boston</span><span class='op'>)</span>

<span class='va'>lda.class_3</span> <span class='op'>&lt;-</span> <span class='va'>lda.pred_3</span><span class='op'>$</span><span class='va'>class</span>

<span class='fu'><a href='https://rdrr.io/r/base/table.html'>table</a></span><span class='op'>(</span><span class='va'>lda.class_3</span>, <span class='va'>test_boston</span><span class='op'>$</span><span class='va'>median_crime_in_tract</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>           
lda.class_3  0  1
          0 70 16
          1  6 60</code></pre>
</div>
<p><strong>Results Model Choice LDA 3:</strong> As seen above this
subset of predictors has decreased the misclassification error rate as
compared to the previous models using just the most statistically
significant predictors in LDA. The correct classification rate is
around 85% here which is a slight increase from previous models.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='va'>lda.class_3</span> <span class='op'>==</span> <span class='va'>test_boston</span><span class='op'>$</span><span class='va'>median_crime_in_tract</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.8552632</td>
</tr>
</tbody>
</table>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/sum.html'>sum</a></span><span class='op'>(</span><span class='va'>lda.pred_3</span><span class='op'>$</span><span class='va'>posterior</span><span class='op'>[</span>, <span class='fl'>1</span><span class='op'>]</span> <span class='op'>&gt;=</span> <span class='fl'>.5</span><span class='op'>)</span><span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">86</td>
</tr>
</tbody>
</table>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/sum.html'>sum</a></span><span class='op'>(</span><span class='va'>lda.pred_3</span><span class='op'>$</span><span class='va'>posterior</span><span class='op'>[</span>, <span class='fl'>1</span><span class='op'>]</span> <span class='op'>&lt;</span> <span class='fl'>.5</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">66</td>
</tr>
</tbody>
</table>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='va'>lda.fit_3</span><span class='op'>)</span>
</code></pre>
</div>
<p><img src="ml-homework-2_files/figure-html5/unnamed-chunk-26-1.png" width="624" /></p>
</div>
<p><strong>Model Choice Naive Bayes:</strong> My first model for naive
bayes uses an, nox, rad, and taxes to predict median crime rate.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>2680</span><span class='op'>)</span>

<span class='va'>nb.fit_1</span> <span class='op'>&lt;-</span> <span class='fu'>naiveBayes</span><span class='op'>(</span><span class='va'>median_crime_in_tract</span> <span class='op'>~</span> <span class='va'>zn</span> <span class='op'>+</span> <span class='va'>nox</span> <span class='op'>+</span><span class='va'>rad</span> <span class='op'>+</span>
                         <span class='va'>tax</span> , data <span class='op'>=</span> <span class='va'>Boston_over_median</span>, <span class='va'>in_training</span><span class='op'>)</span>

<span class='va'>nb.fit_1</span>
</code></pre>
</div>
<pre><code>
Naive Bayes Classifier for Discrete Predictors

Call:
naiveBayes.default(x = X, y = Y, laplace = laplace)

A-priori probabilities:
Y
  0   1 
0.5 0.5 

Conditional probabilities:
   zn
Y        [,1]      [,2]
  0 21.525692 29.319808
  1  1.201581  4.798611

   nox
Y        [,1]       [,2]
  0 0.4709711 0.05559789
  1 0.6384190 0.09870365

   rad
Y        [,1]     [,2]
  0  4.158103 1.659121
  1 14.940711 9.529843

   tax
Y       [,1]     [,2]
  0 305.7431  87.4837
  1 510.7312 167.8553</code></pre>
</div>
<p><strong>Results 1 Naive Bayes:</strong> As can be seen from the error
rates below the first naive bayes model correctly classifies the
predictions 83% of the time whihc is similar to the results of the
previous LDA models.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>2680</span><span class='op'>)</span>

<span class='va'>nb.class_1</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>nb.fit_1</span>, <span class='va'>test_boston</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/base/table.html'>table</a></span><span class='op'>(</span><span class='va'>nb.class_1</span>, <span class='va'>test_boston</span><span class='op'>$</span><span class='va'>median_crime_in_tract</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">0</th>
<th style="text-align: right;">1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">0</td>
<td style="text-align: right;">65</td>
<td style="text-align: right;">15</td>
</tr>
<tr class="even">
<td style="text-align: left;">1</td>
<td style="text-align: right;">11</td>
<td style="text-align: right;">61</td>
</tr>
</tbody>
</table>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='va'>nb.class_1</span> <span class='op'>==</span>  <span class='va'>test_boston</span><span class='op'>$</span><span class='va'>median_crime_in_tract</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.8289474</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Model Choice 2 Naive Bayes:</strong> As can be seen below the
next model choice uses the same statistically significant predictors
according to their p-values in logsitic regression to see if this will
improve the prediction of Naive Bayes.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>382</span><span class='op'>)</span>

<span class='va'>nb.fit_2</span> <span class='op'>&lt;-</span> <span class='fu'>naiveBayes</span><span class='op'>(</span><span class='va'>median_crime_in_tract</span> <span class='op'>~</span> <span class='va'>zn</span> <span class='op'>+</span> <span class='va'>nox</span> <span class='op'>+</span> <span class='va'>dis</span> <span class='op'>+</span> <span class='va'>rad</span> <span class='op'>+</span> 
              <span class='va'>ptratio</span> <span class='op'>+</span> <span class='va'>medv</span> , data <span class='op'>=</span> <span class='va'>Boston_over_median</span>, subset <span class='op'>=</span> <span class='va'>in_training</span><span class='op'>)</span>

<span class='va'>nb.fit_2</span>
</code></pre>
</div>
<pre><code>
Naive Bayes Classifier for Discrete Predictors

Call:
naiveBayes.default(x = X, y = Y, laplace = laplace)

A-priori probabilities:
Y
  0   1 
0.5 0.5 

Conditional probabilities:
   zn
Y        [,1]     [,2]
  0 23.161017 30.10405
  1  1.265537  4.93395

   nox
Y        [,1]       [,2]
  0 0.4684520 0.05410754
  1 0.6392147 0.10448031

   dis
Y       [,1]     [,2]
  0 5.085899 2.084295
  1 2.537347 1.180086

   rad
Y       [,1]     [,2]
  0  4.19209 1.626256
  1 13.92655 9.545955

   ptratio
Y       [,1]     [,2]
  0 17.85706 1.836210
  1 18.95932 2.414571

   medv
Y       [,1]      [,2]
  0 25.25424  6.828791
  1 20.23842 10.349862</code></pre>
</div>
<p><strong>Naive Bayes model 2 Results:</strong> The inclusion of 6
variables, as opposed to 4 slightly improves the correct classification
rate of our model, in this case, about a percent.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>2680</span><span class='op'>)</span>

<span class='va'>nb.class_2</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>nb.fit_2</span>, <span class='va'>test_boston</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/base/table.html'>table</a></span><span class='op'>(</span><span class='va'>nb.class_2</span>, <span class='va'>test_boston</span><span class='op'>$</span><span class='va'>median_crime_in_tract</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">0</th>
<th style="text-align: right;">1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">0</td>
<td style="text-align: right;">61</td>
<td style="text-align: right;">9</td>
</tr>
<tr class="even">
<td style="text-align: left;">1</td>
<td style="text-align: right;">15</td>
<td style="text-align: right;">67</td>
</tr>
</tbody>
</table>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='va'>nb.class_2</span> <span class='op'>==</span>  <span class='va'>test_boston</span><span class='op'>$</span><span class='va'>median_crime_in_tract</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.8421053</td>
</tr>
</tbody>
</table>
</div>
<p>training_boston &lt;- Boston_over_median[in_training,]</p>
<p>test_boston &lt;- Boston_over_median[-in_training,]</p>
<p><strong>Model Choice 3 naive Bayes:</strong> For this naive bayes I
will be using the categorical variables in addition to nox and number of
rooms to see the impact of these two categorical variables with the two
indicators of density and pollution.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>282</span><span class='op'>)</span>

<span class='va'>nb.fit_3</span> <span class='op'>&lt;-</span> <span class='fu'>naiveBayes</span><span class='op'>(</span><span class='va'>median_crime_in_tract</span> <span class='op'>~</span> <span class='va'>nox</span> <span class='op'>+</span> <span class='va'>chas</span> <span class='op'>+</span><span class='va'>rad</span> <span class='op'>+</span> 
                         <span class='va'>rm</span> , data <span class='op'>=</span> <span class='va'>Boston_over_median</span>, subset <span class='op'>=</span> <span class='va'>in_training</span><span class='op'>)</span>

<span class='va'>nb.fit_3</span>
</code></pre>
</div>
<pre><code>
Naive Bayes Classifier for Discrete Predictors

Call:
naiveBayes.default(x = X, y = Y, laplace = laplace)

A-priori probabilities:
Y
  0   1 
0.5 0.5 

Conditional probabilities:
   nox
Y        [,1]       [,2]
  0 0.4684520 0.05410754
  1 0.6392147 0.10448031

   chas
Y         [,1]      [,2]
  0 0.06214689 0.2421070
  1 0.10169492 0.3031041

   rad
Y       [,1]     [,2]
  0  4.19209 1.626256
  1 13.92655 9.545955

   rm
Y       [,1]      [,2]
  0 6.407825 0.5381020
  1 6.174492 0.8282674</code></pre>
</div>
<p><strong>Model Evaluation Naive Bayes 3:</strong> As can be seen from
the results below the naive Bayes with these variables included performs
very well improving the number of correctly identified cross validated
points to about 88%.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>235</span><span class='op'>)</span>

<span class='va'>nb.class_3</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>nb.fit_3</span>, <span class='va'>test_boston</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/base/table.html'>table</a></span><span class='op'>(</span><span class='va'>nb.class_3</span>, <span class='va'>test_boston</span><span class='op'>$</span><span class='va'>median_crime_in_tract</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">0</th>
<th style="text-align: right;">1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">0</td>
<td style="text-align: right;">73</td>
<td style="text-align: right;">14</td>
</tr>
<tr class="even">
<td style="text-align: left;">1</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">62</td>
</tr>
</tbody>
</table>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='va'>nb.class_3</span> <span class='op'>==</span>  <span class='va'>test_boston</span><span class='op'>$</span><span class='va'>median_crime_in_tract</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.8881579</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Model Choice 1 KNN:</strong> Using nox and rad as our
variables below we see that 2 nearest neighbors results in a 98% rate of
correct identifications.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>777</span><span class='op'>)</span>

<span class='va'>train.X</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/cbind.html'>cbind</a></span><span class='op'>(</span><span class='va'>Boston_over_median</span><span class='op'>$</span><span class='va'>nox</span>, <span class='va'>Boston_over_median</span><span class='op'>$</span><span class='va'>rad</span><span class='op'>)</span><span class='op'>[</span><span class='va'>in_training</span>, <span class='op'>]</span>

<span class='va'>test.X</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/cbind.html'>cbind</a></span><span class='op'>(</span><span class='va'>Boston_over_median</span><span class='op'>$</span><span class='va'>nox</span>, <span class='va'>Boston_over_median</span><span class='op'>$</span><span class='va'>rad</span><span class='op'>)</span><span class='op'>[</span><span class='op'>-</span><span class='va'>in_training</span>, <span class='op'>]</span>

<span class='va'>train.median</span> <span class='op'>&lt;-</span> <span class='va'>Boston_over_median</span><span class='op'>$</span><span class='va'>median_crime_in_tract</span><span class='op'>[</span><span class='va'>in_training</span><span class='op'>]</span>

<span class='va'>knn_pred_1</span> <span class='op'>&lt;-</span> <span class='fu'>knn</span><span class='op'>(</span><span class='va'>train.X</span>, <span class='va'>test.X</span>, <span class='va'>train.median</span>, k<span class='op'>=</span><span class='fl'>2</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/base/table.html'>table</a></span><span class='op'>(</span><span class='va'>knn_pred_1</span>, <span class='va'>test_boston</span><span class='op'>$</span><span class='va'>median_crime_in_tract</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">0</th>
<th style="text-align: right;">1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">0</td>
<td style="text-align: right;">74</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;">1</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">75</td>
</tr>
</tbody>
</table>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='va'>knn_pred_1</span> <span class='op'>==</span> <span class='va'>test_boston</span><span class='op'>$</span><span class='va'>median_crime_in_tract</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.9802632</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Model Choice 2 KNN:</strong> As can be seen below using these
two variables and 3 nearest neighbors decreases the number of correctly
identified points in the test set slightly. Continuing to 4 nearest
neighbors afterwards we see this trend continue.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>377</span><span class='op'>)</span>

<span class='va'>knn_pred_2</span> <span class='op'>&lt;-</span> <span class='fu'>knn</span><span class='op'>(</span><span class='va'>train.X</span>, <span class='va'>test.X</span>, <span class='va'>train.median</span>, k<span class='op'>=</span><span class='fl'>3</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/base/table.html'>table</a></span><span class='op'>(</span><span class='va'>knn_pred_2</span>, <span class='va'>test_boston</span><span class='op'>$</span><span class='va'>median_crime_in_tract</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>          
knn_pred_2  0  1
         0 72  1
         1  4 75</code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='va'>knn_pred_2</span> <span class='op'>==</span> <span class='va'>test_boston</span><span class='op'>$</span><span class='va'>median_crime_in_tract</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.9671053</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Model Choice 3 KNN:</strong></p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>377</span><span class='op'>)</span>

<span class='va'>knn_pred_3</span> <span class='op'>&lt;-</span> <span class='fu'>knn</span><span class='op'>(</span><span class='va'>train.X</span>, <span class='va'>test.X</span>, <span class='va'>train.median</span>, k<span class='op'>=</span><span class='fl'>4</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/base/table.html'>table</a></span><span class='op'>(</span><span class='va'>knn_pred_3</span>, <span class='va'>test_boston</span><span class='op'>$</span><span class='va'>median_crime_in_tract</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>          
knn_pred_3  0  1
         0 70  1
         1  6 75</code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='va'>knn_pred_3</span> <span class='op'>==</span> <span class='va'>test_boston</span><span class='op'>$</span><span class='va'>median_crime_in_tract</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.9539474</td>
</tr>
</tbody>
</table>
</div>
<p><strong>KNN-Results:</strong> According to the KNNs above the
results of suggests that 2 nearest neighbors have the lowest amount of
misclassifications for the nox and rad variables.</p>
<h3 id="ch.-5-exercise-2">Ch. 5, Exercise 2</h3>
<p><strong>basis:</strong> We will now derive the probability that a
given observation is part of a bootstrap sample. Suppose that we obtain
a bootstrap sample from a set of n observations.</p>
<h4 id="a">(a)</h4>
<p><strong>Question:</strong> What is the probability that the first
bootstrap observation is not the jth observation from the original
sample? Justify your answer.</p>
<p><strong>Answer:</strong> The probability that the first bootstrap
observation is the jth observation from the original sample of n
observations is 1/n.This means the probability of the converse, that it
is <strong>not</strong> the jth observation is the total probability 1 -
1/n</p>
<h4 id="b">(b)</h4>
<p><strong>Question:</strong> What is the probability that the second
bootstrap observation is not the jth observation from the original
sample?</p>
<p><strong>Answer:</strong> The probability the second bootstrap
observation is not the jth observation is the same as the first since
bootstrapping uses replacement so the probability of each observation
being drawn does not change from bootstrap to bootstrap even if the
number of interest is drawn. As the authors state that since there is
replacement the same observation can occur more than once in the
bootstrap data set (211) so the second observation has the same
probability as the first of being the jth observation,</p>
<h4 id="c">(c)</h4>
<p><strong>Question:</strong> Argue that the probability that the jth
observation is not in the bootstrap sample is (1 - 1/n)^n.</p>
<p><strong>Answer:</strong> The probability that the jth observation is
not in the boot is (1 - 1/n)^n.This is because a the probability for a
single observation is (1-1/n), as there is replacement the probability
of drawing the jth observation does not change from bootstrap to
bootstrap or draw to draw. As a result the probability of jth
observation in an entire bootstrap sample is the product of every single
bootstrap observation not being j, so because we have n observations to
choose from our probability of not having any one in particular
observation is the probability of not drawing jth to the power of the
number of observations.</p>
<h4 id="d">(d)</h4>
<p><strong>Question:</strong> When n = 5, what is the probability that
the jth observation is in the bootstrap sample?</p>
<p><strong>Answer:</strong> As seen below, the probability that the jth
observation is in the bootstrap is 0.67232, this is because the
probability of <strong>not</strong> drawing an observation is (1-1/n)^n
so the probability of drawing one must be one minus this value as seen
below.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='op'>(</span><span class='fl'>1</span><span class='op'>-</span><span class='op'>(</span><span class='fl'>1</span> <span class='op'>-</span> <span class='fl'>1</span><span class='op'>/</span><span class='fl'>5</span><span class='op'>)</span><span class='op'>^</span><span class='fl'>5</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.67232</td>
</tr>
</tbody>
</table>
</div>
<h4 id="e">(e)</h4>
<p><strong>Question:</strong> When n = 100, what is the probability that
the jth observation is in the bootstrap sample?</p>
<p><strong>Answer:</strong> In this case when n = 100 the probability
that the jth observation is in the bootstrap sample is 0.6339677 or
63.39677%</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='op'>(</span><span class='fl'>1</span><span class='op'>-</span><span class='op'>(</span><span class='fl'>1</span> <span class='op'>-</span> <span class='fl'>1</span><span class='op'>/</span><span class='fl'>100</span><span class='op'>)</span><span class='op'>^</span><span class='fl'>100</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.6339677</td>
</tr>
</tbody>
</table>
</div>
<h4 id="f">(f)</h4>
<p><strong>Question:</strong> When n = 10, 000, what is the probability
that the jth observation is in the bootstrap sample?</p>
<p><strong>Answer:</strong> In this case when n = 10,000 the probability
that the jth observation is in the bootstrap sample is 0.632139 or
63.2139%</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='op'>(</span><span class='fl'>1</span><span class='op'>-</span><span class='op'>(</span><span class='fl'>1</span> <span class='op'>-</span> <span class='fl'>1</span><span class='op'>/</span><span class='fl'>10000</span><span class='op'>)</span><span class='op'>^</span><span class='fl'>10000</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.632139</td>
</tr>
</tbody>
</table>
</div>
<h3 id="g">(g)</h3>
<p><strong>Question:</strong> Create a plot that displays, for each
integer value of n from 1 to 100,000, the probability that the jth
observation is in the bootstrap sample. Comment on what you observe.</p>
<p><strong>Answer:</strong> Below I have plotted an integer value from 0
to 100000 using the colon command. After this I calculate the
probability that the observation is in the dataset using 1 - the
probability that it is not in the dataset which is (1-(1 -
1/possible_integers)^possible_integers), the inverse of the prior
problems. For clarity I have also used the prior n-sizes of 5, 100, and
10,000. As can be seen the data appears to have a negative exponential
relationship that eventually reaches a minimum probability near 0.63 no
matter how larger the number of bootstraps we take is.</p>
<div class="layout-chunk" data-layout="l-body">
<p><img src="ml-homework-2_files/figure-html5/unnamed-chunk-45-1.png" width="624" /></p>
</div>
<div class="layout-chunk" data-layout="l-body">
<p><img src="ml-homework-2_files/figure-html5/unnamed-chunk-46-1.png" width="624" /></p>
</div>
<div class="layout-chunk" data-layout="l-body">
<p><img src="ml-homework-2_files/figure-html5/unnamed-chunk-47-1.png" width="624" /></p>
</div>
<h4 id="h">(h)</h4>
<p><strong>Question:</strong> We will now investigate numerically the
probability that a bootstrap sample of size n = 100 contains the jth
observation. Here j = 4. We repeatedly create bootstrap samples, and
each time we record whether or not the fourth observation is contained
in the bootstrap sample.</p>
<p><strong>Answer:</strong> For the loop below the authors use a
replication function with an empty vector, NA, this is then done 10,000
times. Next this goes into a loop with i in 1 through 10000. Next this
function added a sample with replacement from 1:00, sees if it equals 4,
sums the number of samples equal to 4 are greater than zero, this is
then stored in the store which is then expressed by taking its
mean.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>222222</span><span class='op'>)</span>

<span class='va'>store</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/rep.html'>rep</a></span><span class='op'>(</span><span class='cn'>NA</span>, <span class='fl'>10000</span><span class='op'>)</span> 

<span class='kw'>for</span><span class='op'>(</span><span class='va'>i</span> <span class='kw'>in</span> <span class='fl'>1</span><span class='op'>:</span><span class='fl'>10000</span><span class='op'>)</span><span class='op'>{</span>
   
<span class='va'>store</span><span class='op'>[</span><span class='va'>i</span><span class='op'>]</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/sum.html'>sum</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/sample.html'>sample</a></span><span class='op'>(</span><span class='fl'>1</span><span class='op'>:</span><span class='fl'>100</span>, rep<span class='op'>=</span><span class='cn'>TRUE</span><span class='op'>)</span> <span class='op'>==</span> <span class='fl'>4</span><span class='op'>)</span> <span class='op'>&gt;</span> <span class='fl'>0</span> 

<span class='op'>}</span>

<span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='va'>store</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>[1] 0.6362</code></pre>
</div>
<p><strong>Question:</strong> Comment on the results obtained.</p>
<p><strong>Answer continued:</strong> The results of the function are
0.6362, this suggests that as the number of samples increases the
likelihood of observing a specific jth observation in an n out of 100 in
an increasingly large number of bootstraps with replacement approaches
0.636.</p>
<h3 id="ch.-5-exercise-3">Ch. 5, Exercise 3</h3>
<p><strong>Basis:</strong> We now review k-fold cross-validation.</p>
<h4 id="part-a">Part (a)</h4>
<p><strong>Question:</strong> Explain how k-fold cross-validation is
implemented.</p>
<p><strong>Answer:</strong> A k-folds cross validation method is
implemented by randomly diving sets of observations in our data into
groups, in this case they are known as folds. The data is divided k
times and the first fold, which we refer to as the validation set is
then removed and the k-1 folds leftover are then fit using an analysis
method, we then validate the model that we got from the model with the
data not in the fold to see how accurately the model predicts the left
out data. This process is then repeated for all k-folds that were not
the first and were used to fit the original model. Iterating through
this process results in a cross validation estimate in the form of
errors between the predicted values from the model using k-1 and the
true values in the left out k-fold.</p>
<h4 id="part-b">Part (b)</h4>
<p><strong>Question:</strong> What are the advantages and disadvantages
of k-fold cross-validation relative to:</p>
<h5 id="part-i.">Part i.</h5>
<p><strong>Question:</strong> The validation set approach?</p>
<p><strong>Answer:</strong> The validation set approach faces the issue
of insufficient data being used to construct its model. Since the method
can only divide the data in half its estimates can do a poor job
predicting the left out set because it contains so much data that could
be reflective of the relationship between predictors and responses. This
can result in variance in comparing the predictions from the modeling
set to the validation set. As the authors also point out the validation
set approach is fitting on fewer observations it is likely to
overestimate test error rate. The disadvantage of k-folds compared to
validation set approach.</p>
<h5 id="part-ii.">Part ii.</h5>
<p><strong>Question:</strong> LOOCV?</p>
<p><strong>Answer:</strong> Leave one out cross validation is
essentially a special case of k-folds cross validation where the number
of k folds is the total number of observations in the dataset, minus
one. This approach is n-1 k-folds on the dataset and as a result it has
little randomness in its selection thus it has an extremely small amount
of variance between its predictions since a vast majority of data is
used to make predictions that can only vary significantly from one point
that is not used. Depending on the size of the dataset cross validating
one for every point could take a great deal of computational power.
Unlike the validation set leave-one-out-cross-validation will greatly
underestimate the test error rates since its prediction only excludes a
single point. However in k-folds a number of folds that is not
computationally intensive or accounts for a larger difference between
folds that allow for randomness in the subsets that can give a better
sense of how errors are being made as they will be validated on many
more points. As a result a number of k-folds can be chosen that is not 2
or n-1, this k can be determined in such a way that it likely has more
bias than loocv, but balances the excessively high variance from 2 folds
or validation set, and the excessively low variance of loocv.</p>
<h3 id="ch.-5-exercise-5">Ch. 5, Exercise 5</h3>
<p><strong>Basis:</strong> In Chapter 4, we used logistic regression to
predict the probability of default using income and balance on the
Default data set. We will now estimate the test error of this logistic
regression model using the validation set approach. Do not forget to set
a random seed before beginning your analysis.</p>
<h4 id="a-1">(a)</h4>
<p><strong>Question:</strong> Fit a logistic regression model that uses
income and balance to predict default.</p>
<p><strong>Answer:</strong> Below is my first equation labelled
inc_bal_logit which uses the default data and a binomial family within a
glm to model a logistic regression predicting whether of not an
individual defaults based on the income and their balance of debt.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>777</span><span class='op'>)</span>


<span class='va'>inc_bal_logit</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/glm.html'>glm</a></span><span class='op'>(</span><span class='va'>default</span> <span class='op'>~</span> <span class='va'>income</span> <span class='op'>+</span> <span class='va'>balance</span>,  data <span class='op'>=</span> <span class='va'>Default</span>, family <span class='op'>=</span> <span class='st'>"binomial"</span><span class='op'>)</span>

<span class='va'>inc_bal_logit</span>
</code></pre>
</div>
<pre><code>
Call:  glm(formula = default ~ income + balance, family = &quot;binomial&quot;, 
    data = Default)

Coefficients:
(Intercept)       income      balance  
 -1.154e+01    2.081e-05    5.647e-03  

Degrees of Freedom: 9999 Total (i.e. Null);  9997 Residual
Null Deviance:      2921 
Residual Deviance: 1579     AIC: 1585</code></pre>
</div>
<h4 id="b-1">(b)</h4>
<p><strong>Basis:</strong> Using the validation set approach, estimate
the test error of this model. In order to do this, you must perform the
following steps:</p>
<h5 id="i.">i.</h5>
<p><strong>Question:</strong> Split the sample set into a training set
and a validation set.</p>
<p><strong>Answer:</strong> First I split the sample set into training
and validation by sampling the data using the total number of rows in
the dataset nrow(Default) and diving it in half by sampling the
nrow(Default), nrow(Default)/2 times. This amounts to sampling from
10000 rows 5000 times randomly. Next I split the data into a validation
and training set by choosing rows equivalent to those in my training set
and not in my training set.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>777</span><span class='op'>)</span>

<span class='va'>train5_5_1</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/sample.html'>sample</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>Default</span><span class='op'>)</span>, <span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>Default</span><span class='op'>)</span><span class='op'>/</span><span class='fl'>2</span><span class='op'>)</span>

<span class='va'>default_training</span> <span class='op'>&lt;-</span> <span class='va'>Default</span><span class='op'>[</span><span class='va'>train5_5_1</span>,<span class='op'>]</span>

<span class='va'>default_validation</span> <span class='op'>&lt;-</span> <span class='va'>Default</span><span class='op'>[</span><span class='op'>-</span><span class='va'>train5_5_1</span>,<span class='op'>]</span>
</code></pre>
</div>
</div>
<h5 id="ii.">ii.</h5>
<p><strong>Question:</strong> Fit a multiple logistic regression model
using only the training observations.</p>
<p><strong>Answer:</strong> Next I fit a logistic regression using only
my training observations which I defined above as default_training</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>777</span><span class='op'>)</span>

<span class='va'>inc_bal_logit_ii</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/glm.html'>glm</a></span><span class='op'>(</span><span class='va'>default</span> <span class='op'>~</span> <span class='va'>income</span> <span class='op'>+</span> <span class='va'>balance</span>,  family <span class='op'>=</span> <span class='st'>"binomial"</span>, data <span class='op'>=</span> <span class='va'>default_training</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<h5 id="iii.">iii.</h5>
<p><strong>Question:</strong> Obtain a prediction of default status for
each individual in the validation set by computing the posterior
probability of default for that individual, and classifying the
individual to the default category if the posterior probability is
greater than 0.5.</p>
<p><strong>Answer:</strong> I then predict whether or not an individual
in the validation set defaults by using the predict() function which
takes my function inc_bal_logit_ii and my dataset, in this case the
validation set default_validation, I then choose response as this is the
type of prediction we are interested in rather than terms.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>777</span><span class='op'>)</span>

<span class='va'>default_estimates</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>inc_bal_logit_ii</span>, <span class='va'>default_validation</span>,  type<span class='op'>=</span><span class='st'>"response"</span><span class='op'>)</span>

<span class='va'>classification</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/ifelse.html'>ifelse</a></span><span class='op'>(</span><span class='va'>default_estimates</span><span class='op'>&gt;</span><span class='fl'>0.5</span>,<span class='st'>"Yes"</span>,<span class='st'>"No"</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<h5 id="iv.">iv.</h5>
<p><strong>Question:</strong> Compute the validation set error, which is
the fraction of the observations in the validation set that are
misclassified.</p>
<p><strong>Answer:</strong> I then compute the validation set error by
taking the mean of the number of classification outcomes that are not
equal to their true values in the default_validation datasets default
column.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='va'>classification</span> <span class='op'>!=</span> <span class='va'>default_validation</span><span class='op'>$</span><span class='va'>default</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>[1] 0.0256</code></pre>
</div>
<h4 id="a-split-2">(a) (Split 2)</h4>
<p><strong>Question:</strong> Fit a logistic regression model that uses
income and balance to predict default.</p>
<p><strong>Answer:</strong> In the subsequent question I repeat my model
using different splits acquired by changing the seed which dictates the
random generation of all random generation in the model through the
sampling split.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>908</span><span class='op'>)</span>

<span class='va'>inc_bal_logit</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/glm.html'>glm</a></span><span class='op'>(</span><span class='va'>default</span> <span class='op'>~</span> <span class='va'>income</span> <span class='op'>+</span> <span class='va'>balance</span>,  data <span class='op'>=</span> <span class='va'>Default</span>, 
                     family <span class='op'>=</span> <span class='st'>"binomial"</span><span class='op'>)</span>

<span class='va'>inc_bal_logit</span>
</code></pre>
</div>
<pre><code>
Call:  glm(formula = default ~ income + balance, family = &quot;binomial&quot;, 
    data = Default)

Coefficients:
(Intercept)       income      balance  
 -1.154e+01    2.081e-05    5.647e-03  

Degrees of Freedom: 9999 Total (i.e. Null);  9997 Residual
Null Deviance:      2921 
Residual Deviance: 1579     AIC: 1585</code></pre>
</div>
<h4 id="b-split-2">(b) (Split 2)</h4>
<p><strong>Basis:</strong> Using the validation set approach, estimate
the test error of this model. In order to do this, you must perform the
following steps:</p>
<h5 id="i.-1">i.</h5>
<p><strong>Question:</strong> Split the sample set into a training set
and a validation set.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>908</span><span class='op'>)</span>

<span class='va'>train5_5_1</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/sample.html'>sample</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>Default</span><span class='op'>)</span>, <span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>Default</span><span class='op'>)</span><span class='op'>/</span><span class='fl'>2</span><span class='op'>)</span>

<span class='va'>default_training</span><span class='op'>&lt;-</span><span class='va'>Default</span><span class='op'>[</span><span class='va'>train5_5_1</span>,<span class='op'>]</span>

<span class='va'>default_validation</span><span class='op'>&lt;-</span><span class='va'>Default</span><span class='op'>[</span><span class='op'>-</span><span class='va'>train5_5_1</span>,<span class='op'>]</span>
</code></pre>
</div>
</div>
<h5 id="ii.-1">ii.</h5>
<p><strong>Question:</strong> Fit a multiple logistic regression model
using only the training observations.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>908</span><span class='op'>)</span>

<span class='va'>inc_bal_logit_ii</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/glm.html'>glm</a></span><span class='op'>(</span><span class='va'>default</span> <span class='op'>~</span> <span class='va'>income</span> <span class='op'>+</span> <span class='va'>balance</span>,  family <span class='op'>=</span> <span class='st'>"binomial"</span>, 
                        data <span class='op'>=</span> <span class='va'>default_training</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<h5 id="iii.-1">iii.</h5>
<p><strong>Question:</strong> Obtain a prediction of default status for
each individual in the validation set by computing the posterior
probability of default for that individual, and classifying the
individual to the default category if the posterior probability is
greater than 0.5.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>908</span><span class='op'>)</span>

<span class='va'>default_estimates</span><span class='op'>&lt;-</span><span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>inc_bal_logit_ii</span>, <span class='va'>default_validation</span>, 
                           type<span class='op'>=</span><span class='st'>"response"</span><span class='op'>)</span>

<span class='va'>classification</span><span class='op'>&lt;-</span><span class='fu'><a href='https://rdrr.io/r/base/ifelse.html'>ifelse</a></span><span class='op'>(</span><span class='va'>default_estimates</span><span class='op'>&gt;</span><span class='fl'>0.5</span>,<span class='st'>"Yes"</span>,<span class='st'>"No"</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<h5 id="iv.-1">iv.</h5>
<p><strong>Question:</strong> Compute the validation set error, which is
the fraction of the observations in the validation set that are
misclassified.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='va'>classification</span> <span class='op'>!=</span> <span class='va'>default_validation</span><span class='op'>$</span><span class='va'>default</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>[1] 0.0286</code></pre>
</div>
<h4 id="a-split-3">(a) (Split 3)</h4>
<p><strong>Question:</strong> Fit a logistic regression model that uses
income and balance to predict default.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>2000</span><span class='op'>)</span>

<span class='va'>inc_bal_logit</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/glm.html'>glm</a></span><span class='op'>(</span><span class='va'>default</span> <span class='op'>~</span> <span class='va'>income</span> <span class='op'>+</span> <span class='va'>balance</span>,  data <span class='op'>=</span> <span class='va'>Default</span>,
                     family <span class='op'>=</span> <span class='st'>"binomial"</span><span class='op'>)</span>

<span class='va'>inc_bal_logit</span>
</code></pre>
</div>
<pre><code>
Call:  glm(formula = default ~ income + balance, family = &quot;binomial&quot;, 
    data = Default)

Coefficients:
(Intercept)       income      balance  
 -1.154e+01    2.081e-05    5.647e-03  

Degrees of Freedom: 9999 Total (i.e. Null);  9997 Residual
Null Deviance:      2921 
Residual Deviance: 1579     AIC: 1585</code></pre>
</div>
<h4 id="b-split-3">(b) (Split 3)</h4>
<p><strong>Basis:</strong> Using the validation set approach, estimate
the test error of this model. In order to do this, you must perform the
following steps:</p>
<h5 id="i.-2">i.</h5>
<p><strong>Question:</strong> Split the sample set into a training set
and a validation set.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>2000</span><span class='op'>)</span>

<span class='va'>train5_5_1</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/sample.html'>sample</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>Default</span><span class='op'>)</span>, <span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>Default</span><span class='op'>)</span><span class='op'>/</span><span class='fl'>2</span><span class='op'>)</span>

<span class='va'>default_training</span><span class='op'>&lt;-</span><span class='va'>Default</span><span class='op'>[</span><span class='va'>train5_5_1</span>,<span class='op'>]</span>

<span class='va'>default_validation</span><span class='op'>&lt;-</span><span class='va'>Default</span><span class='op'>[</span><span class='op'>-</span><span class='va'>train5_5_1</span>,<span class='op'>]</span>
</code></pre>
</div>
</div>
<h5 id="ii.-2">ii.</h5>
<p><strong>Question:</strong> Fit a multiple logistic regression model
using only the training observations.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>2000</span><span class='op'>)</span>

<span class='va'>inc_bal_logit_ii</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/glm.html'>glm</a></span><span class='op'>(</span><span class='va'>default</span> <span class='op'>~</span> <span class='va'>income</span> <span class='op'>+</span> <span class='va'>balance</span>,  family <span class='op'>=</span> <span class='st'>"binomial"</span>, 
                        data <span class='op'>=</span> <span class='va'>default_training</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<h5 id="iii.-2">iii.</h5>
<p><strong>Question:</strong> Obtain a prediction of default status for
each individual in the validation set by computing the posterior
probability of default for that individual, and classifying the
individual to the default category if the posterior probability is
greater than 0.5.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>2000</span><span class='op'>)</span>

<span class='va'>default_estimates</span><span class='op'>&lt;-</span><span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>inc_bal_logit_ii</span>, <span class='va'>default_validation</span>,  
                           type<span class='op'>=</span><span class='st'>"response"</span><span class='op'>)</span>

<span class='va'>classification</span><span class='op'>&lt;-</span><span class='fu'><a href='https://rdrr.io/r/base/ifelse.html'>ifelse</a></span><span class='op'>(</span><span class='va'>default_estimates</span><span class='op'>&gt;</span><span class='fl'>0.5</span>,<span class='st'>"Yes"</span>,<span class='st'>"No"</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<h5 id="iv.-2">iv.</h5>
<p><strong>Question:</strong> Compute the validation set error, which is
the fraction of the observations in the validation set that are
misclassified.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='va'>classification</span> <span class='op'>!=</span> <span class='va'>default_validation</span><span class='op'>$</span><span class='va'>default</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>[1] 0.0294</code></pre>
</div>
<h4 id="a-split-4">(a) (Split 4)</h4>
<p><strong>Question:</strong> Fit a logistic regression model that uses
income and balance to predict default.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>2</span><span class='op'>)</span>

<span class='va'>inc_bal_logit</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/glm.html'>glm</a></span><span class='op'>(</span><span class='va'>default</span> <span class='op'>~</span> <span class='va'>income</span> <span class='op'>+</span> <span class='va'>balance</span>,  data <span class='op'>=</span> <span class='va'>Default</span>,
                     family <span class='op'>=</span> <span class='st'>"binomial"</span><span class='op'>)</span>

<span class='va'>inc_bal_logit</span>
</code></pre>
</div>
<pre><code>
Call:  glm(formula = default ~ income + balance, family = &quot;binomial&quot;, 
    data = Default)

Coefficients:
(Intercept)       income      balance  
 -1.154e+01    2.081e-05    5.647e-03  

Degrees of Freedom: 9999 Total (i.e. Null);  9997 Residual
Null Deviance:      2921 
Residual Deviance: 1579     AIC: 1585</code></pre>
</div>
<h4 id="b-split-4">(b) (Split 4)</h4>
<p><strong>Basis:</strong> Using the validation set approach, estimate
the test error of this model. In order to do this, you must perform the
following steps:</p>
<h5
id="i.-split-the-sample-set-into-a-training-set-and-a-validation-set.">i.
Split the sample set into a training set and a validation set.</h5>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>2</span><span class='op'>)</span>

<span class='va'>train5_5_1</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/sample.html'>sample</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>Default</span><span class='op'>)</span>, <span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>Default</span><span class='op'>)</span><span class='op'>/</span><span class='fl'>2</span><span class='op'>)</span>

<span class='va'>default_training</span><span class='op'>&lt;-</span><span class='va'>Default</span><span class='op'>[</span><span class='va'>train5_5_1</span>,<span class='op'>]</span>

<span class='va'>default_validation</span><span class='op'>&lt;-</span><span class='va'>Default</span><span class='op'>[</span><span class='op'>-</span><span class='va'>train5_5_1</span>,<span class='op'>]</span>
</code></pre>
</div>
</div>
<h5
id="ii.-fit-a-multiple-logistic-regression-model-using-only-the-training-observations.">ii.
Fit a multiple logistic regression model using only the training
observations.</h5>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>2</span><span class='op'>)</span>

<span class='va'>inc_bal_logit_ii</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/glm.html'>glm</a></span><span class='op'>(</span><span class='va'>default</span> <span class='op'>~</span> <span class='va'>income</span> <span class='op'>+</span> <span class='va'>balance</span>, 
                        family <span class='op'>=</span> <span class='st'>"binomial"</span>, data <span class='op'>=</span> <span class='va'>default_training</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<h5
id="iii.-obtain-a-prediction-of-default-status-for-each-individual-in">iii.
Obtain a prediction of default status for each individual in</h5>
<p>the validation set by computing the posterior probability of default
for that individual, and classifying the individual to the default
category if the posterior probability is greater than 0.5.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>2</span><span class='op'>)</span>

<span class='va'>default_estimates</span><span class='op'>&lt;-</span><span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>inc_bal_logit_ii</span>, <span class='va'>default_validation</span>,  
                           type<span class='op'>=</span><span class='st'>"response"</span><span class='op'>)</span>

<span class='va'>classification</span><span class='op'>&lt;-</span><span class='fu'><a href='https://rdrr.io/r/base/ifelse.html'>ifelse</a></span><span class='op'>(</span><span class='va'>default_estimates</span><span class='op'>&gt;</span><span class='fl'>0.5</span>,<span class='st'>"Yes"</span>,<span class='st'>"No"</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<h5
id="iv.-compute-the-validation-set-error-which-is-the-fraction-of-the-observations-in-the-validation-set-that-are-misclassified.">iv.
Compute the validation set error, which is the fraction of the
observations in the validation set that are misclassified.</h5>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='va'>classification</span> <span class='op'>!=</span> <span class='va'>default_validation</span><span class='op'>$</span><span class='va'>default</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>[1] 0.0238</code></pre>
</div>
<h4 id="d-1">(d)</h4>
<p><strong>Question:</strong> Now consider a logistic regression model
that predicts the probability of default using income, balance, and a
dummy variable for student. Estimate the test error for this model using
the validation set approach. Comment on whether or not including a dummy
variable for student leads to a reduction in the test error rate.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>222</span><span class='op'>)</span>


<span class='va'>student_bal_logit</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/glm.html'>glm</a></span><span class='op'>(</span><span class='va'>default</span> <span class='op'>~</span> <span class='va'>income</span> <span class='op'>+</span> <span class='va'>balance</span> <span class='op'>+</span> <span class='va'>student</span>,  
                         data <span class='op'>=</span> <span class='va'>Default</span>, family <span class='op'>=</span> <span class='st'>"binomial"</span><span class='op'>)</span>

<span class='va'>student_bal_logit</span>
</code></pre>
</div>
<pre><code>
Call:  glm(formula = default ~ income + balance + student, family = &quot;binomial&quot;, 
    data = Default)

Coefficients:
(Intercept)       income      balance   studentYes  
 -1.087e+01    3.033e-06    5.737e-03   -6.468e-01  

Degrees of Freedom: 9999 Total (i.e. Null);  9996 Residual
Null Deviance:      2921 
Residual Deviance: 1572     AIC: 1580</code></pre>
</div>
<h4 id="b-2">(b)</h4>
<p><strong>Basis:</strong> Using the validation set approach, estimate
the test error of this model. In order to do this, you must perform the
following steps:</p>
<h5
id="i.-split-the-sample-set-into-a-training-set-and-a-validation-set.-1">i.
Split the sample set into a training set and a validation set.</h5>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>222</span><span class='op'>)</span>

<span class='va'>train5_5_1</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/sample.html'>sample</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>Default</span><span class='op'>)</span>, <span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>Default</span><span class='op'>)</span><span class='op'>/</span><span class='fl'>2</span><span class='op'>)</span>

<span class='va'>default_training</span><span class='op'>&lt;-</span><span class='va'>Default</span><span class='op'>[</span><span class='va'>train5_5_1</span>,<span class='op'>]</span>

<span class='va'>default_validation</span><span class='op'>&lt;-</span><span class='va'>Default</span><span class='op'>[</span><span class='op'>-</span><span class='va'>train5_5_1</span>,<span class='op'>]</span>
</code></pre>
</div>
</div>
<h5
id="ii.-fit-a-multiple-logistic-regression-model-using-only-the-training-observations.-1">ii.
Fit a multiple logistic regression model using only the training
observations.</h5>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>222</span><span class='op'>)</span>

<span class='va'>student_bal_logit_ii</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/glm.html'>glm</a></span><span class='op'>(</span><span class='va'>default</span> <span class='op'>~</span> <span class='va'>income</span> <span class='op'>+</span> <span class='va'>balance</span>,  
                            family <span class='op'>=</span> <span class='st'>"binomial"</span>, data <span class='op'>=</span> <span class='va'>default_training</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<h5
id="iii.-obtain-a-prediction-of-default-status-for-each-individual-in-1">iii.
Obtain a prediction of default status for each individual in</h5>
<p>the validation set by computing the posterior probability of default
for that individual, and classifying the individual to the default
category if the posterior probability is greater than 0.5.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>222</span><span class='op'>)</span>

<span class='va'>default_estimates_student</span><span class='op'>&lt;-</span><span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>student_bal_logit_ii</span>, <span class='va'>default_validation</span>,  
                                   type<span class='op'>=</span><span class='st'>"response"</span><span class='op'>)</span>

<span class='va'>classification_students</span><span class='op'>&lt;-</span><span class='fu'><a href='https://rdrr.io/r/base/ifelse.html'>ifelse</a></span><span class='op'>(</span><span class='va'>default_estimates_student</span><span class='op'>&gt;</span><span class='fl'>0.5</span>,<span class='st'>"Yes"</span>,<span class='st'>"No"</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<h5
id="iv.-compute-the-validation-set-error-which-is-the-fraction-of-the-observations-in-the-validation-set-that-are-misclassified.-1">iv.
Compute the validation set error, which is the fraction of the
observations in the validation set that are misclassified.</h5>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='va'>classification</span> <span class='op'>!=</span> <span class='va'>default_validation</span><span class='op'>$</span><span class='va'>default</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>[1] 0.0492</code></pre>
</div>
<h4 id="d-2">(d)</h4>
<p><strong>Answer:</strong> It appears that including the dummy variable
for student increases the missclassification error rate in the dataset,
in this way the inclusion of the variable is not beneficial in reducing
the error rate of the function as it increases from under 0.03, or less
than 3% to 0.0468 using my seed which is 4.68% which thus decreases the
accuracy of the model. This could suggest that student variable leads to
some calculations in the model that are more likely to mis-classify.
Students take on a great volume of debt at a young age, however they do
so as an investment for later earnings, as a result students with high
debt may be misclassified by the regression due to their likely high
debt.</p>
<h3 id="ch.-5-exercise-9">Ch. 5, Exercise 9</h3>
<p><strong>Basis:</strong> We will now consider the Boston housing data
set, from the ISLR2 library.</p>
<h4 id="a-2">(a)</h4>
<p><strong>Question:</strong> Based on this data set, provide an
estimate for the population mean of medv. Call this estimate mu.</p>
<p><strong>Answer:</strong> My calculation for the population mean is
found my taking the mean of the entire column of medv from the Boston
dataset which is stored as mu</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>mu</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='va'>Boston</span><span class='op'>$</span><span class='va'>medv</span><span class='op'>)</span>

<span class='va'>mu</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">22.53281</td>
</tr>
</tbody>
</table>
</div>
<h4 id="b-3">(b)</h4>
<p><strong>Question:</strong> Provide an estimate of the standard error
of mu. Interpret this result.</p>
<p>Hint: We can compute the standard error of the sample mean by
dividing the sample standard deviation by the square root of the number
of observations.</p>
<p><strong>Answer:</strong> Using the hint I label the standard error of
mu as the standard deviation of the Boston$medv column and diving it by
the number of observations nrow in the Boston dataset which has its
square root taken before deiving the standard deviation, this is then
stored in se_mu</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>se_mu</span><span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/sd.html'>sd</a></span><span class='op'>(</span><span class='va'>Boston</span><span class='op'>$</span><span class='va'>medv</span><span class='op'>)</span><span class='op'>/</span><span class='fu'><a href='https://rdrr.io/r/base/MathFun.html'>sqrt</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>Boston</span><span class='op'>)</span><span class='op'>)</span>

<span class='va'>se_mu</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.4088611</td>
</tr>
</tbody>
</table>
</div>
<h4 id="c-1">(c)</h4>
<p><strong>Question:</strong> Now estimate the standard error of mu
using the bootstrap. How does this compare to your answer from (b)?</p>
<p><strong>Answer:</strong> In order to estimate the standard error of
mu using a bootstrap I must first create a function that can be used by
boot, which will return our statistic of interest. In this case the data
is Boston and its column medv Boston$medv which are placed in the first
observation of the bootstrap. Next I need a statistic writing the
function I needed it to specify the dataframe and column index as
described in the chapter 5 lab. Next I need this function to return the
mean of this dataframes specified index. Following the chapter 5 lab I
use 1000 replicates of the bootstrap.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='op'>?</span><span class='va'>boot</span>
<span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>547</span><span class='op'>)</span>

<span class='va'>mu_function</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>data</span>, <span class='va'>index</span><span class='op'>)</span> <span class='op'>{</span>
 <span class='va'>mu_for_function</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='va'>data</span><span class='op'>[</span><span class='va'>index</span><span class='op'>]</span><span class='op'>)</span>
 <span class='kw'><a href='https://rdrr.io/r/base/function.html'>return</a></span><span class='op'>(</span><span class='va'>mu_for_function</span><span class='op'>)</span>
<span class='op'>}</span>


<span class='fu'>boot</span><span class='op'>(</span><span class='va'>Boston</span><span class='op'>$</span><span class='va'>medv</span>, <span class='va'>mu_function</span> , R <span class='op'>=</span> <span class='fl'>1000</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>
ORDINARY NONPARAMETRIC BOOTSTRAP


Call:
boot(data = Boston$medv, statistic = mu_function, R = 1000)


Bootstrap Statistics :
    original     bias    std. error
t1* 22.53281 0.01013577   0.4090362</code></pre>
</div>
<h4 id="d-3">(d)</h4>
<p><strong>Question:</strong> Based on your bootstrap estimate from (c),
provide a 95 % confidence interval for the mean of medv. Compare it to
the results obtained using t.test(Boston$medv).</p>
<p><strong>Hint:</strong> You can approximate a 95 % confidence interval
using the formula [mu - 2SE(mu), mu + 2SEmu].</p>
<p><strong>Answer:</strong> I create the 95% confidence interval from my
bootstrap using my mean estimate plus and minus 2 standard deviations,
this estimate is 22.53281 as the mean I then use the hint formula addin
or subtracting 2 standard errors.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/stats/sd.html'>sd</a></span><span class='op'>(</span><span class='va'>Boston</span><span class='op'>$</span><span class='va'>medv</span><span class='op'>)</span><span class='op'>/</span><span class='fu'><a href='https://rdrr.io/r/base/MathFun.html'>sqrt</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>Boston</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>)</span><span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.4088611</td>
</tr>
</tbody>
</table>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>ci_95_boot</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span>
 <span class='op'>(</span><span class='fl'>22.53281</span><span class='op'>-</span><span class='fl'>2</span><span class='op'>*</span><span class='fl'>0.4132074</span><span class='op'>)</span>,<span class='op'>(</span><span class='fl'>22.53281</span><span class='op'>+</span><span class='fl'>2</span><span class='op'>*</span><span class='fl'>0.4132074</span><span class='op'>)</span>
   <span class='op'>)</span>
<span class='va'>ci_95_boot</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">21.70640</td>
</tr>
<tr class="even">
<td style="text-align: right;">23.35922</td>
</tr>
</tbody>
</table>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/stats/t.test.html'>t.test</a></span><span class='op'>(</span><span class='va'>Boston</span><span class='op'>$</span><span class='va'>medv</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>
    One Sample t-test

data:  Boston$medv
t = 55.111, df = 505, p-value &lt; 2.2e-16
alternative hypothesis: true mean is not equal to 0
95 percent confidence interval:
 21.72953 23.33608
sample estimates:
mean of x 
 22.53281 </code></pre>
</div>
<p><strong>Answer Continued:</strong> The t-test estimates (21.72953
23.33608) and our bootstrap estimates (21.70640 23.35922). The
differences in the lower tail are below:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fl'>21.72953</span><span class='op'>-</span><span class='fl'>21.70640</span>
</code></pre>
</div>
<pre><code>[1] 0.02313</code></pre>
</div>
<p><strong>Answer Continued:</strong> The differences in the upper tail
are below:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fl'>23.33608</span> <span class='op'>-</span> <span class='fl'>23.35922</span>
</code></pre>
</div>
<pre><code>[1] -0.02314</code></pre>
</div>
<p><strong>Answer Continued:</strong> The difference is similar in both
directions on the lower tail the t-test estimates a slightly higher
upper tail and a slightly higher on the lower tail.</p>
<h4 id="e-1">(e)</h4>
<p><strong>Question:</strong> Based on this data set, provide an
estimate, mu_med, for the median value of medv in the population.</p>
<p><strong>Answer:</strong> I calculate this median value as the median
of the Boston dataset and medv column using the median function which is
saved as mu_med.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>mu_med</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/median.html'>median</a></span><span class='op'>(</span><span class='va'>Boston</span><span class='op'>$</span><span class='va'>medv</span><span class='op'>)</span>

<span class='va'>mu_med</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">21.2</td>
</tr>
</tbody>
</table>
</div>
<h4 id="f-1">(f)</h4>
<p><strong>Question:</strong> We now would like to estimate the standard
error of mu_med.Unfortunately, there is no simple formula for computing
the standard error of the median. Instead, estimate the standard error
of the median using the bootstrap. Comment on your findings.</p>
<p><strong>Answer:</strong> Below I create a function to take the median
of a dataset and its column index that works the same way as the prior
mean function.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>8282</span><span class='op'>)</span>

<span class='va'>median_function</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>data</span>, <span class='va'>index</span><span class='op'>)</span> <span class='op'>{</span>
 <span class='va'>median_for_function</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/median.html'>median</a></span><span class='op'>(</span><span class='va'>data</span><span class='op'>[</span><span class='va'>index</span><span class='op'>]</span><span class='op'>)</span>
 <span class='kw'><a href='https://rdrr.io/r/base/function.html'>return</a></span><span class='op'>(</span><span class='va'>median_for_function</span><span class='op'>)</span>
<span class='op'>}</span>

<span class='fu'>boot</span><span class='op'>(</span><span class='va'>Boston</span><span class='op'>$</span><span class='va'>medv</span>, <span class='va'>median_function</span>, R <span class='op'>=</span> <span class='fl'>1000</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>
ORDINARY NONPARAMETRIC BOOTSTRAP


Call:
boot(data = Boston$medv, statistic = median_function, R = 1000)


Bootstrap Statistics :
    original   bias    std. error
t1*     21.2 -0.01325    0.381356</code></pre>
</div>
<p><strong>Answer Continued:</strong> The resulting standard error from
this bootstrap is 0.381356.</p>
<h4 id="g-1">(g)</h4>
<p><strong>Question:</strong> Based on this data set, provide an
estimate for the tenth percentile of medv in Boston census tracts. Call
this quantity mu_0.1. (You can use the quantile() function.)</p>
<p><strong>Answer:</strong> Below I calculate the 10th percentile using
the Boston dataset and the medv column and the quantile function, then
specifying the quantile between [0 and 1] I use 0.1 as this is the 10th
percentile</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>mu_0.1</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/quantile.html'>quantile</a></span><span class='op'>(</span><span class='va'>Boston</span><span class='op'>$</span><span class='va'>medv</span>, <span class='fl'>0.1</span><span class='op'>)</span>

<span class='va'>mu_0.1</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">10%</td>
<td style="text-align: right;">12.75</td>
</tr>
</tbody>
</table>
</div>
<h4 id="h-1">(h)</h4>
<p><strong>Question:</strong> Use the bootstrap to estimate the standard
error of mu_0.1. Comment on your findings.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>8282</span><span class='op'>)</span>


<span class='va'>tenth_quantile_function</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>data</span>, <span class='va'>index</span><span class='op'>)</span> <span class='op'>{</span>
 <span class='va'>tenth_for_function</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/quantile.html'>quantile</a></span><span class='op'>(</span><span class='va'>data</span><span class='op'>[</span><span class='va'>index</span><span class='op'>]</span>, <span class='fl'>0.1</span><span class='op'>)</span>
 <span class='kw'><a href='https://rdrr.io/r/base/function.html'>return</a></span><span class='op'>(</span><span class='va'>tenth_for_function</span><span class='op'>)</span>
<span class='op'>}</span>

<span class='fu'>boot</span><span class='op'>(</span><span class='va'>Boston</span><span class='op'>$</span><span class='va'>medv</span>, <span class='va'>tenth_quantile_function</span>, R <span class='op'>=</span> <span class='fl'>1000</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>
ORDINARY NONPARAMETRIC BOOTSTRAP


Call:
boot(data = Boston$medv, statistic = tenth_quantile_function, 
    R = 1000)


Bootstrap Statistics :
    original  bias    std. error
t1*    12.75  -0.004   0.5122122</code></pre>
</div>
<p><strong>Answer:</strong> In this case I estimate the average quantile
estimate of medv in the 10th percentile as 12.75 in the bootstrap as
compared to 12.75 in the dataset. It appears that both function capture
the same exact medv point as the 10th percentile in the dataset.</p>
<h3 id="ch.-6-exercise-2">Ch. 6, Exercise 2</h3>
<p><strong>Basis:</strong> For parts (a) through (c), indicate which of
i. through iv. is correct. Justify your answer.</p>
<h4 id="a-3">(a)</h4>
<p><strong>Question:</strong> The lasso, relative to least squares,
is:</p>
<h5
id="i.-more-flexible-and-hence-will-give-improved-prediction-accuracy-when-its-increase-in-bias-is-less-than-its-decrease-in-variance.">i.
More flexible and hence will give improved prediction accuracy when its
increase in bias is less than its decrease in variance.</h5>
<p><strong>Answer:</strong> Compared to least squares the lasso
regression is less flexible since it will perform variable selection,
this is meant to reduce overfitting which least squares will often do.
In this case the answer is correct because lassos are not more flexible
to least squares since they do not fit as many variables and thus will
not fit the data as closely.</p>
<h5
id="ii.-more-flexible-and-hence-will-give-improved-prediction-accuracy-when-its-increase-in-variance-is-less-than-its-decrease-in-bias.">ii.
More flexible and hence will give improved prediction accuracy when its
increase in variance is less than its decrease in bias.</h5>
<p><strong>Answer:</strong> This answer is is incorrect as in the case
of the first one because a</p>
<h5
id="iii.-less-flexible-and-hence-will-give-improved-prediction-accuracy-when-its-increase-in-bias-is-less-than-its-decrease-in-variance.">iii.
Less flexible and hence will give improved prediction accuracy when its
increase in bias is less than its decrease in variance.</h5>
<p><strong>Answer:</strong> This answer is correct, as established lasso
is less flexible as it will reduce non-influential parameters to zero
depending on its tuning parameters but will always be less flexible than
the regression it is based on if the tuning parameter is non-zero.
However as the authors in ISLR explain the lasso solution can yield a
reduction in variance at the expense of a small increase in bias, in
cases when least squares is over fit and results in inaccurate
predictions, which this case follows.</p>
<h5
id="iv.-less-flexible-and-hence-will-give-improved-prediction-accuracy-when-its-increase-in-variance-is-less-than-its-decrease-in-bias.">iv.
Less flexible and hence will give improved prediction accuracy when its
increase in variance is less than its decrease in bias.</h5>
<p><strong>Answer:</strong> This answer is incorrect as lasso regression
is formulated in order to reduce overfitting and thus variance on fitted
data. As a result, and relative to least squares, lasso is not used to
reduce bias, but instead variance in estimates.</p>
<h4 id="b-4">(b)</h4>
<p><strong>Question:</strong> ridge regression relative to least
squares.</p>
<h5
id="i.-more-flexible-and-hence-will-give-improved-prediction-accuracy-when-its-increase-in-bias-is-less-than-its-decrease-in-variance.-1">i.
More flexible and hence will give improved prediction accuracy when its
increase in bias is less than its decrease in variance.</h5>
<p><strong>Answer:</strong> As in the first response the ridge
regression also is less flexible than least squares because it removes
variables, or at least most their coefficients closer to zero, however,
unlike lasso, it keeps the p-varaibles within the model. In this case
making variables smaller does not allow the ridge regression to follow
the data as closely as least squares as increasing the shrinkage
coefficient leads to a decrease in flexibility by making the fit closer,
the second part is correct however as the ridge regression will decrease
variance as overfitting is also reduced..</p>
<h5
id="ii.-more-flexible-and-hence-will-give-improved-prediction-accuracy-when-its-increase-in-variance-is-less-than-its-decrease-in-bias.-1">ii.
More flexible and hence will give improved prediction accuracy when its
increase in variance is less than its decrease in bias.</h5>
<p><strong>Answer:</strong> This response is also incorrect as if the
shrinkage coefficient is sufficiently small the function is less
flexible, the second part is also incorrect as the function is valuable
when it gives improved prediction accuracy when its increase in
<strong>bias</strong> is sufficiently less than its decrease in
variance.</p>
<h5
id="iii.-less-flexible-and-hence-will-give-improved-prediction-accuracy-when-its-increase-in-bias-is-less-than-its-decrease-in-variance.-1">iii.
Less flexible and hence will give improved prediction accuracy when its
increase in bias is less than its decrease in variance.</h5>
<p><strong>Answer:</strong> This response is again correct, here like
lasso, we reduce the influence of non-influential parameters by moving
them towards, or to zero, as a result these variables will lose
influence thus not being as likely to overfit as a result, the function
may not be able to avoid bias as much as linear regression but can
greatly reduce the variance due to overfitting.</p>
<h5
id="iv.-less-flexible-and-hence-will-give-improved-prediction-accuracy-when-its-increase-in-variance-is-less-than-its-decrease-in-bias.-1">iv.
Less flexible and hence will give improved prediction accuracy when its
increase in variance is less than its decrease in bias.</h5>
<p><strong>Answer:</strong> This is again incorrect as it will decrease
variance rather than bias in its efforts not to overfit.</p>
<h4 id="c-2">(c)</h4>
<p><strong>Question:</strong> non-linear methods relative to least
squares.</p>
<h5
id="i.-more-flexible-and-hence-will-give-improved-prediction-accuracy-when-its-increase-in-bias-is-less-than-its-decrease-in-variance.-2">i.
More flexible and hence will give improved prediction accuracy when its
increase in bias is less than its decrease in variance.</h5>
<p><strong>Answer:</strong> Non-linear methods are more flexible than
least squares, however, in most cases it is useful when its increase in
bias is less than its decrease in</p>
<h5
id="ii.-more-flexible-and-hence-will-give-improved-prediction-accuracy-when-its-increase-in-variance-is-less-than-its-decrease-in-bias.-2">ii.
More flexible and hence will give improved prediction accuracy when its
increase in variance is less than its decrease in bias.</h5>
<p><strong>Answer:</strong> Non-linear methods are more flexible as they
will fit predictions more closely, they are also able to afford more
predictive accuracy when their increase in variance is less than their
increase in bias, since bias is the difference between a parameters and
the expected value of a statistic the non-linear model will give better
predictions when its increase in variance is less than its increase in
bias. This is due to the bias variance trade-off, here out non-linear
model fits data more closely thus it has the potential to have higher
variance if it is overfit than linear regression, as a result if that
increase in variance is sufficiency less than its decrease in bias due
to its closer fit than we consider it a stronger model for the scenario
thus this answer is correct.</p>
<h5
id="iii.-less-flexible-and-hence-will-give-improved-prediction-accuracy-when-its-increase-in-bias-is-less-than-its-decrease-in-variance.-2">iii.
Less flexible and hence will give improved prediction accuracy when its
increase in bias is less than its decrease in variance.</h5>
<p><strong>Answer:</strong> This answer is incorrect as non-linear
models are more flexible than linear ones.</p>
<h5
id="iv.-less-flexible-and-hence-will-give-improved-prediction-accuracy-when-its-increase-in-variance-is-less-than-its-decrease-in-bias.-2">iv.
Less flexible and hence will give improved prediction accuracy when its
increase in variance is less than its decrease in bias.</h5>
<p><strong>Answer:</strong> This answer is incorrect as non-linear
models are more flexible than linear ones.</p>
<h3 id="islr-ch.-6-exercise-9">ISLR Ch. 6, Exercise 9</h3>
<p><strong>Basis:</strong> In this exercise, we will predict the number
of applications received using the other variables in the College data
set.</p>
<h4 id="a-4">(a)</h4>
<p><strong>Question:</strong> Split the data set into a training set and
a test set.</p>
<p><strong>Answer:</strong> I split the data into training and test set
using 1 through the number of rows in the dataset and sampling it
nrow(College)*0.8 times which works out to taking 621.6 row samples with
replacement equals FALSE, this equates to and 80%, 20% split in the
training and test sets. I specify the college_training as the 80% of
College data I specified as my training. Next I find the test set using
the converse of the training rows.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>9292</span><span class='op'>)</span>

<span class='va'>train_College_numbers</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/sample.html'>sample</a></span><span class='op'>(</span><span class='fl'>1</span><span class='op'>:</span><span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>College</span><span class='op'>)</span>, <span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>College</span><span class='op'>)</span><span class='op'>*</span><span class='fl'>0.8</span>,
                                replace <span class='op'>=</span> <span class='cn'>FALSE</span><span class='op'>)</span>

<span class='va'>college_training</span> <span class='op'>&lt;-</span> <span class='va'>College</span><span class='op'>[</span><span class='va'>train_College_numbers</span>,<span class='op'>]</span>

<span class='va'>college_test</span> <span class='op'>&lt;-</span> <span class='va'>College</span><span class='op'>[</span><span class='op'>-</span><span class='va'>train_College_numbers</span>,<span class='op'>]</span>
</code></pre>
</div>
</div>
<h4 id="b-5">(b)</h4>
<p><strong>Question:</strong> Fit a linear model using least squares on
the training set, and report the test error obtained.</p>
<p><strong>Answer:</strong> I fit a least squares on my 80% training set
below using all variables since we will be using a ridge regression that
later account for the number of variables we should use as the ridge
moves their coefficients towards zero.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>9292</span><span class='op'>)</span>

<span class='va'>least_squares_college</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/glm.html'>glm</a></span><span class='op'>(</span><span class='va'>Grad.Rate</span> <span class='op'>~</span><span class='va'>.</span> , data<span class='op'>=</span><span class='va'>college_training</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p><strong>Answer:</strong> I then use the predict function using my
least squares function and my test data to make prediction for my error
rate. I express the test error as the mean square error, which is
calculated as 142.0359</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>9292</span><span class='op'>)</span>

<span class='va'>pred_college_for_mse</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>least_squares_college</span>, newdata<span class='op'>=</span><span class='va'>college_test</span><span class='op'>)</span>

<span class='va'>MSE_college_test</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='op'>(</span><span class='va'>college_test</span><span class='op'>$</span><span class='va'>Grad.Rate</span><span class='op'>-</span><span class='va'>pred_college_for_mse</span><span class='op'>)</span><span class='op'>^</span><span class='fl'>2</span><span class='op'>)</span>

<span class='va'>MSE_college_test</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">190.8233</td>
</tr>
</tbody>
</table>
</div>
<h4 id="c-3">(c)</h4>
<p><strong>Question:</strong> Fit a ridge regression model on the
training set, with lambda chosen by cross-validation. Report the test
error obtained.</p>
<p><strong>Answer:</strong> Below I make a grid of values that is a
sequence of 10 to -2 of length 100 which goes from 10^10 to 10^(-2)
creates a set of selected values. In order to fit a ridge model using
cross validation I split the model into training and test set. Using the
glmnet() function I then plug in my x-ridge model matrix and the y-ridge
being the true values from the graduation rate column of the college
dataset. This results in a dimension of 18 by 100.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>9292</span><span class='op'>)</span>

<span class='va'>x_ridge</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/model.matrix.html'>model.matrix</a></span><span class='op'>(</span><span class='va'>Grad.Rate</span> <span class='op'>~</span> <span class='va'>.</span>, <span class='va'>College</span><span class='op'>)</span><span class='op'>[</span>, <span class='op'>-</span><span class='fl'>1</span><span class='op'>]</span> 

<span class='va'>y_ridge</span> <span class='op'>&lt;-</span> <span class='va'>College</span><span class='op'>$</span><span class='va'>Grad.Rate</span>

<span class='va'>grid</span> <span class='op'>&lt;-</span> <span class='fl'>10</span><span class='op'>^</span><span class='fu'><a href='https://rdrr.io/r/base/seq.html'>seq</a></span><span class='op'>(</span><span class='fl'>10</span>, <span class='op'>-</span><span class='fl'>2</span>, length <span class='op'>=</span> <span class='fl'>100</span><span class='op'>)</span>

<span class='va'>ridge.mod</span> <span class='op'>&lt;-</span> <span class='fu'>glmnet</span><span class='op'>(</span><span class='va'>x_ridge</span>, <span class='va'>y_ridge</span>, alpha <span class='op'>=</span> <span class='fl'>0</span>, lambda <span class='op'>=</span> <span class='va'>grid</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/base/dim.html'>dim</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/stats/coef.html'>coef</a></span><span class='op'>(</span><span class='va'>ridge.mod</span><span class='op'>)</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>[1]  18 100</code></pre>
</div>
<p><strong>Answer:</strong> Below I then split my data into an 80% 20%
split between training and test sets. These values are stored in the
train_ridge and test_ridge variables.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>9292</span><span class='op'>)</span>

<span class='va'>train_ridge</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/sample.html'>sample</a></span><span class='op'>(</span><span class='fl'>1</span><span class='op'>:</span><span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>x_ridge</span><span class='op'>)</span>, <span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>x_ridge</span><span class='op'>)</span><span class='op'>*</span><span class='fl'>0.8</span> <span class='op'>)</span> 

<span class='va'>test_ridge</span> <span class='op'>&lt;-</span> <span class='op'>(</span><span class='op'>-</span><span class='va'>train_ridge</span><span class='op'>)</span>

<span class='va'>y.test_ridge</span> <span class='op'>&lt;-</span> <span class='va'>y_ridge</span><span class='op'>[</span><span class='va'>test_ridge</span><span class='op'>]</span>
</code></pre>
</div>
</div>
<p><strong>Answer:</strong> I then use the glmnet() function with an
alpha of 0 which is a ridge penalty in this case. In this scenario the
function is named ridge.mod, this is then put into predict() where it
predicts on the test section of the data.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>9292</span><span class='op'>)</span>

<span class='va'>ridge.mod</span> <span class='op'>&lt;-</span> <span class='fu'>glmnet</span><span class='op'>(</span><span class='va'>x_ridge</span><span class='op'>[</span><span class='va'>train_ridge</span>, <span class='op'>]</span>, <span class='va'>y_ridge</span><span class='op'>[</span><span class='va'>train_ridge</span><span class='op'>]</span>, 
                    alpha <span class='op'>=</span> <span class='fl'>0</span>, lambda <span class='op'>=</span> <span class='va'>grid</span>, thresh <span class='op'>=</span> <span class='fl'>1e-12</span><span class='op'>)</span>

<span class='va'>ridge.pred</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>ridge.mod</span>, s <span class='op'>=</span> <span class='fl'>4</span>, newx <span class='op'>=</span> <span class='va'>x_ridge</span><span class='op'>[</span><span class='va'>test_ridge</span>,<span class='op'>]</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='op'>(</span><span class='va'>ridge.pred</span> <span class='op'>-</span> <span class='va'>y.test_ridge</span><span class='op'>)</span><span class='op'>^</span><span class='fl'>2</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">191.9619</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Answer:</strong> Afterwards we fit the model again using the
glmnet() function ridge.mod using a new x from x_ridge and our x and y
from training. We then access the 18 coefficients below, as can be seen
the ridge moves the coefficients it decides have little impact towns
zero.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>9292</span><span class='op'>)</span>

<span class='va'>ridge.pred</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>ridge.mod</span>, s <span class='op'>=</span> <span class='fl'>0</span>, newx <span class='op'>=</span> <span class='va'>x_ridge</span><span class='op'>[</span><span class='va'>test_ridge</span>, <span class='op'>]</span>, 
                      exact <span class='op'>=</span> <span class='cn'>T</span>, x <span class='op'>=</span> <span class='va'>x_ridge</span><span class='op'>[</span><span class='va'>train_ridge</span>, <span class='op'>]</span>, y <span class='op'>=</span> <span class='va'>y_ridge</span><span class='op'>[</span><span class='va'>train_ridge</span><span class='op'>]</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>ridge.mod</span>, s <span class='op'>=</span> <span class='fl'>0</span>, exact <span class='op'>=</span> <span class='cn'>T</span>, type <span class='op'>=</span> <span class='st'>"coefficients"</span>, 
        x <span class='op'>=</span> <span class='va'>x_ridge</span><span class='op'>[</span><span class='va'>train_ridge</span>, <span class='op'>]</span>, y <span class='op'>=</span> <span class='va'>y_ridge</span><span class='op'>[</span><span class='va'>train_ridge</span><span class='op'>]</span><span class='op'>)</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>:</span><span class='fl'>18</span>, <span class='op'>]</span>
</code></pre>
</div>
<pre><code>  (Intercept)    PrivateYes          Apps        Accept        Enroll 
28.8970053130  4.6799076483  0.0012568714 -0.0008668106  0.0023593568 
    Top10perc     Top25perc   F.Undergrad   P.Undergrad      Outstate 
 0.0468337629  0.1437342449 -0.0004323463 -0.0013350746  0.0008084910 
   Room.Board         Books      Personal           PhD      Terminal 
 0.0021795777  0.0004206020 -0.0017882831  0.1379432456 -0.0702662338 
    S.F.Ratio   perc.alumni        Expend 
 0.0406692785  0.2997380403 -0.0004995716 </code></pre>
</div>
<p><strong>Answer continued:</strong> Next after beginning these tests
we use cross validation to get the optimal tuning parameters from a
number of repetitions using cv.glmnet() in this case it takes our
training values and an alpha of zero to indicate it is a ridge and uses
a number of values of lambda to determine which minimizes mean squared
errors. This is plotted below</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>9292</span><span class='op'>)</span>

<span class='va'>cv.out</span> <span class='op'>&lt;-</span> <span class='fu'>cv.glmnet</span><span class='op'>(</span><span class='va'>x_ridge</span><span class='op'>[</span><span class='va'>train_ridge</span>, <span class='op'>]</span>, <span class='va'>y_ridge</span><span class='op'>[</span><span class='va'>train_ridge</span><span class='op'>]</span>, alpha <span class='op'>=</span> <span class='fl'>0</span><span class='op'>)</span> 

<span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='va'>cv.out</span><span class='op'>)</span>
</code></pre>
</div>
<p><img src="ml-homework-2_files/figure-html5/unnamed-chunk-92-1.png" width="624" /></p>
</div>
<p><strong>Answer continued:</strong> The cv.out we calculated above
outputs a 1se and min lambda for its mean square errors which I access
below to determine the cross validated tuning parameter.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>9292</span><span class='op'>)</span>

<span class='va'>bestlam</span> <span class='op'>&lt;-</span> <span class='va'>cv.out</span><span class='op'>$</span><span class='va'>lambda.min</span>

<span class='va'>bestlam</span>
</code></pre>
</div>
<pre><code>[1] 1.876765</code></pre>
</div>
<p><strong>Answer continued:</strong> Finally we use out predict
function to see what our mean squared error will be for our tuning
parameters than minimizes MSE, in this case it is 191.0022 as seen below
compared to the grid values which yielded a 191.9619 at best.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>9292</span><span class='op'>)</span>

<span class='va'>ridge.pred</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>cv.out</span>, s <span class='op'>=</span> <span class='va'>bestlam</span>, newx <span class='op'>=</span> <span class='va'>x_ridge</span><span class='op'>[</span><span class='va'>test_ridge</span>,<span class='op'>]</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='op'>(</span><span class='va'>ridge.pred</span> <span class='op'>-</span> <span class='va'>y.test_ridge</span><span class='op'>)</span><span class='op'>^</span><span class='fl'>2</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">191.0022</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Answer continued:</strong> The coefficient outputs for the
lambda that minimizes MSE are then outputted below. Here Private school,
per.alumni, Top10perc, and top25perc, along with Phd having coefficients
over 0.05 in predicting the graduation rate.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>9292</span><span class='op'>)</span>

<span class='va'>out</span> <span class='op'>&lt;-</span> <span class='fu'>glmnet</span><span class='op'>(</span><span class='va'>x_ridge</span><span class='op'>[</span><span class='va'>train_ridge</span>, <span class='op'>]</span>, <span class='va'>y_ridge</span><span class='op'>[</span><span class='va'>train_ridge</span><span class='op'>]</span>, alpha <span class='op'>=</span> <span class='fl'>0</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>out</span>, type <span class='op'>=</span> <span class='st'>"coefficients"</span>, s <span class='op'>=</span> <span class='va'>bestlam</span><span class='op'>)</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>:</span><span class='fl'>18</span>, <span class='op'>]</span>
</code></pre>
</div>
<pre><code>  (Intercept)    PrivateYes          Apps        Accept        Enroll 
30.4028107340  4.3857666072  0.0005579653  0.0002846755  0.0002715066 
    Top10perc     Top25perc   F.Undergrad   P.Undergrad      Outstate 
 0.0898592282  0.1170937551 -0.0001524760 -0.0012353250  0.0006590921 
   Room.Board         Books      Personal           PhD      Terminal 
 0.0020270611  0.0001479914 -0.0018704177  0.0918979855 -0.0206644006 
    S.F.Ratio   perc.alumni        Expend 
 0.0319300362  0.2726551009 -0.0002998044 </code></pre>
</div>
<h4 id="d-4">(d)</h4>
<p><strong>Question:</strong> Fit a lasso model on the training set,
with lambda chosen by cross validation. Report the test error obtained,
along with the number of non-zero coefficient estimates.</p>
<p><strong>Answer:</strong> The process of creating the lasso is largely
similar to that of the ridge though here our inital glmnet() takes an
alpha of 1. The plot below this indicates that depending on our choise
of tuning parameter lambda, certain coefficients will become zero.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>9292</span><span class='op'>)</span>

<span class='va'>lasso.mod</span> <span class='op'>&lt;-</span> <span class='fu'>glmnet</span><span class='op'>(</span><span class='va'>x_ridge</span><span class='op'>[</span><span class='va'>train_ridge</span>, <span class='op'>]</span>, <span class='va'>y_ridge</span><span class='op'>[</span><span class='va'>train_ridge</span><span class='op'>]</span>, 
                    alpha <span class='op'>=</span> <span class='fl'>1</span>, lambda <span class='op'>=</span> <span class='va'>grid</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='va'>lasso.mod</span><span class='op'>)</span>
</code></pre>
</div>
<p><img src="ml-homework-2_files/figure-html5/unnamed-chunk-96-1.png" width="624" /></p>
</div>
<p><strong>Answer continued:</strong> We continue this analysis by cross
validation using cv.glmnet() with an alpha of 1 to find the coefficients
that again, minimize the MSE.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>9292</span><span class='op'>)</span>

<span class='va'>cv.out_2</span> <span class='op'>&lt;-</span> <span class='fu'>cv.glmnet</span><span class='op'>(</span><span class='va'>x_ridge</span><span class='op'>[</span><span class='va'>train_ridge</span>, <span class='op'>]</span>, <span class='va'>y_ridge</span><span class='op'>[</span><span class='va'>train_ridge</span><span class='op'>]</span>, alpha <span class='op'>=</span> <span class='fl'>1</span><span class='op'>)</span> 

<span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='va'>cv.out_2</span><span class='op'>)</span>
</code></pre>
</div>
<p><img src="ml-homework-2_files/figure-html5/unnamed-chunk-97-1.png" width="624" /></p>
</div>
<p><strong>Answer continued:</strong> After this cross validation has
been calculated we then access the lambda that minimizes MSE. We then
use the predict function to calculate predictions for our lasso using
the lambda that minimizes MSE this gets a MSE of 190.8808.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>9292</span><span class='op'>)</span>

<span class='va'>bestlam</span> <span class='op'>&lt;-</span> <span class='va'>cv.out_2</span><span class='op'>$</span><span class='va'>lambda.min</span>

<span class='va'>lasso.pred</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>cv.out_2</span>, s <span class='op'>=</span> <span class='va'>bestlam</span>, newx <span class='op'>=</span> <span class='va'>x_ridge</span><span class='op'>[</span><span class='va'>test_ridge</span>,<span class='op'>]</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='op'>(</span><span class='va'>lasso.pred</span> <span class='op'>-</span> <span class='va'>y.test_ridge</span><span class='op'>)</span><span class='op'>^</span><span class='fl'>2</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">190.8808</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Answer continued:</strong> Finally we calculate and show the
coefficients for our equation with the lasso reducing our number of
parameters by moving coefficients towards zero that have low impact.
Here we remove, Accept, Enroll, F.Undergrad, Books, Terminal, and
S.F.Ratio with other values still being reflected in the equation
coefficients.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>9292</span><span class='op'>)</span>

<span class='va'>out</span> <span class='op'>&lt;-</span> <span class='fu'>glmnet</span><span class='op'>(</span><span class='va'>x_ridge</span><span class='op'>[</span><span class='va'>train_ridge</span>, <span class='op'>]</span>, <span class='va'>y_ridge</span><span class='op'>[</span><span class='va'>train_ridge</span><span class='op'>]</span>, 
              alpha <span class='op'>=</span> <span class='fl'>1</span>, lambda <span class='op'>=</span> <span class='va'>grid</span><span class='op'>)</span>

<span class='va'>lasso.coef</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>out</span>, type <span class='op'>=</span> <span class='st'>"coefficients"</span>, s <span class='op'>=</span> <span class='va'>bestlam</span><span class='op'>)</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>:</span><span class='fl'>18</span>, <span class='op'>]</span>

<span class='va'>lasso.coef</span>
</code></pre>
</div>
<pre><code>  (Intercept)    PrivateYes          Apps        Accept        Enroll 
29.8146208578  4.2178703808  0.0006714817  0.0000000000  0.0000000000 
    Top10perc     Top25perc   F.Undergrad   P.Undergrad      Outstate 
 0.0508305488  0.1371884865  0.0000000000 -0.0013060619  0.0007140270 
   Room.Board         Books      Personal           PhD      Terminal 
 0.0020119407  0.0000000000 -0.0016927269  0.0683671684  0.0000000000 
    S.F.Ratio   perc.alumni        Expend 
 0.0000000000  0.2909171513 -0.0002954747 </code></pre>
</div>
<h3 id="ch.-8-exercise-4">Ch. 8, Exercise 4</h3>
<p><strong>Uses</strong> Plots in Figure 8.14.</p>
<h4 id="part-a-1">Part (a)</h4>
<p><strong>Question:</strong> Sketch the tree corresponding to the
partition of the predictor space illustrated in the left-hand panel of
Figure 8.14. The numbers inside the boxes indicate the mean of Y within
each region.</p>
<p><strong>Answer:</strong> Possible Partitions in 8.14 Parent
(x1&lt;1), if not below return 5. All else if x1 is below 1, next
(x2&lt;1, or x2&gt;1) if x2 greater than 1 return 15, if x1&lt;0 less
than 0 return 3, if it is more than 0, but x2 is also less than zero
return 10</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'>treemap</span><span class='op'>)</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/rich-iannone/DiagrammeR'>DiagrammeR</a></span><span class='op'>)</span>
</code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>fig8_1_4</span> <span class='op'>&lt;-</span> <span class='va'>Node</span><span class='op'>$</span><span class='fu'>new</span><span class='op'>(</span><span class='st'>"figure 8.14"</span><span class='op'>)</span>
    <span class='va'>top_node</span> <span class='op'>&lt;-</span> <span class='va'>fig8_1_4</span><span class='op'>$</span><span class='fu'>AddChild</span><span class='op'>(</span><span class='st'>"If x1&lt;1"</span><span class='op'>)</span>
    <span class='va'>return_5</span> <span class='op'>&lt;-</span> <span class='va'>top_node</span><span class='op'>$</span><span class='fu'>AddChild</span><span class='op'>(</span><span class='st'>"5"</span><span class='op'>)</span>
    <span class='va'>second_node</span> <span class='op'>&lt;-</span> <span class='va'>top_node</span><span class='op'>$</span><span class='fu'>AddChild</span><span class='op'>(</span><span class='st'>"If x2&lt;1"</span><span class='op'>)</span>
      <span class='va'>return_15</span> <span class='op'>&lt;-</span> <span class='va'>second_node</span><span class='op'>$</span><span class='fu'>AddChild</span><span class='op'>(</span><span class='st'>"15"</span><span class='op'>)</span>
      <span class='va'>third_node</span> <span class='op'>&lt;-</span> <span class='va'>second_node</span><span class='op'>$</span><span class='fu'>AddChild</span><span class='op'>(</span><span class='st'>"If x1&lt;0"</span><span class='op'>)</span>
        <span class='va'>return_3</span> <span class='op'>&lt;-</span> <span class='va'>third_node</span><span class='op'>$</span><span class='fu'>AddChild</span><span class='op'>(</span><span class='st'>"3"</span><span class='op'>)</span>
          <span class='va'>fourth_node</span> <span class='op'>&lt;-</span>  <span class='va'>third_node</span><span class='op'>$</span><span class='fu'>AddChild</span><span class='op'>(</span><span class='st'>"x2&lt;0"</span><span class='op'>)</span>
              <span class='va'>fifth_node</span> <span class='op'>&lt;-</span>  <span class='va'>fourth_node</span><span class='op'>$</span><span class='fu'>AddChild</span><span class='op'>(</span><span class='st'>"10"</span><span class='op'>)</span>
              <span class='va'>fifth_node</span> <span class='op'>&lt;-</span>  <span class='va'>fourth_node</span><span class='op'>$</span><span class='fu'>AddChild</span><span class='op'>(</span><span class='st'>"0"</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='va'>fig8_1_4</span><span class='op'>)</span>
</code></pre>
</div>
<div id="htmlwidget-777492016de7d1e2f8ec" style="width:624px;height:384px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-777492016de7d1e2f8ec">{"x":{"diagram":"digraph {\n\n\n\n\n  \"1\" [label = \"figure 8.14\", fillcolor = \"#FFFFFF\", fontcolor = \"#000000\"] \n  \"2\" [label = \"If x1<1\", fillcolor = \"#FFFFFF\", fontcolor = \"#000000\"] \n  \"3\" [label = \"5\", fillcolor = \"#FFFFFF\", fontcolor = \"#000000\"] \n  \"4\" [label = \"If x2<1\", fillcolor = \"#FFFFFF\", fontcolor = \"#000000\"] \n  \"5\" [label = \"15\", fillcolor = \"#FFFFFF\", fontcolor = \"#000000\"] \n  \"6\" [label = \"If x1<0\", fillcolor = \"#FFFFFF\", fontcolor = \"#000000\"] \n  \"7\" [label = \"3\", fillcolor = \"#FFFFFF\", fontcolor = \"#000000\"] \n  \"8\" [label = \"x2<0\", fillcolor = \"#FFFFFF\", fontcolor = \"#000000\"] \n  \"9\" [label = \"10\", fillcolor = \"#FFFFFF\", fontcolor = \"#000000\"] \n  \"10\" [label = \"0\", fillcolor = \"#FFFFFF\", fontcolor = \"#000000\"] \n  \"1\"->\"2\" \n  \"2\"->\"3\" \n  \"2\"->\"4\" \n  \"4\"->\"5\" \n  \"4\"->\"6\" \n  \"6\"->\"7\" \n  \"6\"->\"8\" \n  \"8\"->\"9\" \n  \"8\"->\"10\" \n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
<h4 id="part-b-1">Part (b)</h4>
<p><strong>Question:</strong> Create a diagram similar to the left-hand
panel of Figure 8.14, using the tree illustrated in the right-hand panel
of the same figure. You should divide up the predictor space into the
correct regions, and indicate the mean for each region.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='op'>?</span><span class='va'>plot</span>
</code></pre>
</div>
<pre><code>Help on topic &#39;plot&#39; was found in the following packages:

  Package               Library
  base                  /Library/Frameworks/R.framework/Resources/library
  graphics              /Library/Frameworks/R.framework/Versions/4.1/Resources/library


Using the first match ...</code></pre>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='cn'>NA</span>, <span class='cn'>NA</span>, type <span class='op'>=</span> <span class='st'>"n"</span>, xlim <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>0</span>,<span class='fl'>3</span><span class='op'>)</span>, 
     ylim <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='op'>-</span><span class='fl'>1</span>, <span class='fl'>1.25</span><span class='op'>)</span>, xlab <span class='op'>=</span> <span class='st'>"x-2"</span>, ylab <span class='op'>=</span> <span class='st'>"x-1"</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/graphics/lines.html'>lines</a></span><span class='op'>(</span>x <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>1</span>, <span class='fl'>1</span><span class='op'>)</span>, y <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='op'>-</span><span class='fl'>1.0</span>, <span class='fl'>1.20</span><span class='op'>)</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/graphics/lines.html'>lines</a></span><span class='op'>(</span>x <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>2</span>, <span class='fl'>2</span><span class='op'>)</span>, y <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='op'>-</span><span class='fl'>1.0</span>, <span class='fl'>1.20</span><span class='op'>)</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/graphics/lines.html'>lines</a></span><span class='op'>(</span>x <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>0</span>, <span class='fl'>1</span><span class='op'>)</span>, y <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>1</span>, <span class='fl'>1</span><span class='op'>)</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/graphics/lines.html'>lines</a></span><span class='op'>(</span>x <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>1</span>, <span class='fl'>2</span><span class='op'>)</span>, y <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>0</span>, <span class='fl'>0</span><span class='op'>)</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/graphics/text.html'>text</a></span><span class='op'>(</span><span class='fl'>0.5</span>, <span class='fl'>1.2</span> , <span class='st'>"0.63"</span><span class='op'>)</span> 

<span class='fu'><a href='https://rdrr.io/r/graphics/text.html'>text</a></span><span class='op'>(</span><span class='fl'>0.5</span>, <span class='fl'>0.0</span> , <span class='st'>"-1.80"</span><span class='op'>)</span> 

<span class='fu'><a href='https://rdrr.io/r/graphics/text.html'>text</a></span><span class='op'>(</span><span class='fl'>2.5</span>, <span class='op'>-</span><span class='fl'>0.0</span>, <span class='st'>"-2.49"</span><span class='op'>)</span> 

<span class='fu'><a href='https://rdrr.io/r/graphics/text.html'>text</a></span><span class='op'>(</span><span class='fl'>1.5</span>, <span class='op'>-</span><span class='fl'>0.5</span>, <span class='st'>"-1.06"</span><span class='op'>)</span> 

<span class='fu'><a href='https://rdrr.io/r/graphics/text.html'>text</a></span><span class='op'>(</span><span class='fl'>1.5</span>, <span class='fl'>0.5</span>, <span class='st'>"0.21"</span><span class='op'>)</span> 
</code></pre>
</div>
<p><img src="ml-homework-2_files/figure-html5/unnamed-chunk-102-1.png" width="624" /></p>
</div>
<h3 id="ch.-8-exercise-7">Ch. 8, Exercise 7</h3>
<p><strong>Question:</strong> In the lab, we applied random forests to
the Boston data using mtry = 6 and using ntree = 25 and ntree = 500.
Create a plot displaying the test error resulting from random forests on
this data set for a more comprehensive range of values for mtry and
ntree. You can model your plot after Figure 8.10. Describe the results
obtained.</p>
<p><strong>Answer:</strong> I will be modeling my response from that in
figure 8.10, in this case they use 3 m-values being m=p, m=p/2, and
m=sqrt(p), in addition to this I will vary the number of trees in each
case. As seen below, I am using 13, 6.5 rounded up to 7 predictions, and
3.6 rounded up to 4 for the square root of p.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>ncol</a></span><span class='op'>(</span><span class='va'>Boston</span><span class='op'>)</span><span class='op'>-</span><span class='fl'>1</span><span class='op'>)</span>  <span class='op'><a href='https://rdrr.io/pkg/DiagrammeR/man/pipe.html'>%&gt;%</a></span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">13</td>
</tr>
</tbody>
</table>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='op'>(</span><span class='fl'>13</span><span class='op'>/</span><span class='fl'>2</span><span class='op'>)</span> <span class='op'><a href='https://rdrr.io/pkg/DiagrammeR/man/pipe.html'>%&gt;%</a></span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">6.5</td>
</tr>
</tbody>
</table>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/MathFun.html'>sqrt</a></span><span class='op'>(</span><span class='fl'>13</span><span class='op'>)</span><span class='op'>)</span> <span class='op'><a href='https://rdrr.io/pkg/DiagrammeR/man/pipe.html'>%&gt;%</a></span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">3.605551</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Answer Continued:</strong> As in the lab, I will divide my
data into testing and training set, I will use 70% of the data in my
training set for the model</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>888</span><span class='op'>)</span> 

<span class='va'>train_boston_set</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/sample.html'>sample</a></span><span class='op'>(</span><span class='fl'>1</span><span class='op'>:</span><span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>Boston</span><span class='op'>)</span>, <span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>Boston</span><span class='op'>)</span><span class='op'>*</span><span class='fl'>0.7</span><span class='op'>)</span>

<span class='va'>Rf_train_boston</span> <span class='op'>&lt;-</span> <span class='va'>Boston</span><span class='op'>[</span><span class='va'>train_boston_set</span>,<span class='op'>]</span>

<span class='va'>Rf_test_boston</span> <span class='op'>&lt;-</span> <span class='va'>Boston</span><span class='op'>[</span><span class='op'>-</span><span class='va'>train_boston_set</span>,<span class='op'>]</span>

<span class='va'>Boston_rf_mtry_13_ntree_25</span> <span class='op'>&lt;-</span> <span class='fu'>randomForest</span><span class='op'>(</span><span class='va'>medv</span><span class='op'>~</span><span class='va'>.</span> ,subset <span class='op'>=</span> <span class='va'>train_boston_set</span>, data <span class='op'>=</span> <span class='va'>Boston</span>, mtry <span class='op'>=</span> <span class='fl'>13</span>, ntree <span class='op'>=</span> <span class='fl'>25</span><span class='op'>)</span>

<span class='va'>Boston_rf_mtry_7_ntree_25</span> <span class='op'>&lt;-</span> <span class='fu'>randomForest</span><span class='op'>(</span><span class='va'>medv</span><span class='op'>~</span><span class='va'>.</span>,subset <span class='op'>=</span> <span class='va'>train_boston_set</span>, data <span class='op'>=</span> <span class='va'>Boston</span>, mtry <span class='op'>=</span> <span class='fl'>7</span>, ntree <span class='op'>=</span> <span class='fl'>25</span><span class='op'>)</span>

<span class='va'>Boston_rf_mtry_4_ntree_25</span> <span class='op'>&lt;-</span> <span class='fu'>randomForest</span><span class='op'>(</span><span class='va'>medv</span><span class='op'>~</span><span class='va'>.</span>,subset <span class='op'>=</span> <span class='va'>train_boston_set</span>,  data <span class='op'>=</span> <span class='va'>Boston</span>, mtry <span class='op'>=</span> <span class='fl'>4</span>, ntree <span class='op'>=</span> <span class='fl'>25</span><span class='op'>)</span>

<span class='va'>Boston_rf_mtry_13_ntree_100</span> <span class='op'>&lt;-</span> <span class='fu'>randomForest</span><span class='op'>(</span><span class='va'>medv</span><span class='op'>~</span><span class='va'>.</span> ,subset <span class='op'>=</span> <span class='va'>train_boston_set</span>, data <span class='op'>=</span> <span class='va'>Boston</span>, mtry <span class='op'>=</span> <span class='fl'>13</span>, ntree <span class='op'>=</span> <span class='fl'>100</span><span class='op'>)</span>

<span class='va'>Boston_rf_mtry_7_ntree_100</span> <span class='op'>&lt;-</span> <span class='fu'>randomForest</span><span class='op'>(</span><span class='va'>medv</span><span class='op'>~</span><span class='va'>.</span>,subset <span class='op'>=</span> <span class='va'>train_boston_set</span>, data <span class='op'>=</span> <span class='va'>Boston</span>, mtry <span class='op'>=</span> <span class='fl'>7</span>, ntree <span class='op'>=</span> <span class='fl'>100</span><span class='op'>)</span>

<span class='va'>Boston_rf_mtry_4_ntree_100</span> <span class='op'>&lt;-</span><span class='fu'>randomForest</span><span class='op'>(</span><span class='va'>medv</span><span class='op'>~</span><span class='va'>.</span>,subset <span class='op'>=</span> <span class='va'>train_boston_set</span>,  data <span class='op'>=</span> <span class='va'>Boston</span>, mtry <span class='op'>=</span> <span class='fl'>4</span>, ntree <span class='op'>=</span> <span class='fl'>100</span><span class='op'>)</span>

<span class='va'>Boston_rf_mtry_13_ntree_500</span> <span class='op'>&lt;-</span> <span class='fu'>randomForest</span><span class='op'>(</span><span class='va'>medv</span><span class='op'>~</span><span class='va'>.</span> ,subset <span class='op'>=</span> <span class='va'>train_boston_set</span>, data <span class='op'>=</span> <span class='va'>Boston</span>, mtry <span class='op'>=</span> <span class='fl'>13</span>, ntree <span class='op'>=</span> <span class='fl'>500</span><span class='op'>)</span>

<span class='va'>Boston_rf_mtry_7_ntree_500</span><span class='op'>&lt;-</span><span class='fu'>randomForest</span><span class='op'>(</span><span class='va'>medv</span><span class='op'>~</span><span class='va'>.</span>,subset <span class='op'>=</span> <span class='va'>train_boston_set</span>, data <span class='op'>=</span> <span class='va'>Boston</span>, mtry <span class='op'>=</span> <span class='fl'>7</span>, ntree <span class='op'>=</span> <span class='fl'>500</span><span class='op'>)</span>

<span class='va'>Boston_rf_mtry_4_ntree_500</span><span class='op'>&lt;-</span><span class='fu'>randomForest</span><span class='op'>(</span><span class='va'>medv</span><span class='op'>~</span><span class='va'>.</span>,subset <span class='op'>=</span> <span class='va'>train_boston_set</span>,  data <span class='op'>=</span> <span class='va'>Boston</span>, mtry <span class='op'>=</span> <span class='fl'>4</span>, ntree <span class='op'>=</span> <span class='fl'>500</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">
<p><img src="ml-homework-2_files/figure-html5/unnamed-chunk-105-1.png" width="624" /></p>
</div>
<p><strong>Answer continued:</strong> The plot above indicates the
average errors plotted against the number of trees used in the
derivation, in this case I have included a legend as in 8.10 to indicate
both the number of trees used in addition to my comparison between m and
p used in my random forest. In this case it is apparent that trees in
the 500s initially have the lowest mean squared errors when compared to
25 trees, and to a lesser extent, 100 trees. Below I will plot graphs
containing only the 25 trees, 100 trees, and 500 trees.</p>
<div class="layout-chunk" data-layout="l-body">
<p><img src="ml-homework-2_files/figure-html5/unnamed-chunk-106-1.png" width="624" /></p>
</div>
<p><strong>Answer continued:</strong> Comparing the 25 trees to each
other and 100 trees, it does firstly appear that 100 trees decreases the
error rate across the differing m and p values.</p>
<div class="layout-chunk" data-layout="l-body">
<p><img src="ml-homework-2_files/figure-html5/unnamed-chunk-107-1.png" width="624" /></p>
</div>
<p><strong>Answer continued:</strong> Comparing the 100 trees and 500s
trees it also appears that the higher number of trees decreases the
error rate in the data, with all plotted against each other as in the
first graph it does appear that the larger number of trees decreases the
error rate more rapidly as the number of trees increases.</p>
<div class="layout-chunk" data-layout="l-body">
<p><img src="ml-homework-2_files/figure-html5/unnamed-chunk-108-1.png" width="624" /></p>
</div>
<h3 id="ch.-8-exercise-9">Ch. 8, Exercise 9</h3>
<p><strong>Basis:</strong> This problem involves the OJ data set which
is part of the ISLR2 package.</p>
<h4 id="part-a-2">Part (a)</h4>
<p><strong>Question:</strong> Create a training set containing a random
sample of 800 observations, and a test set containing the remaining
observations.</p>
<p><strong>Answer:</strong> In order to take a sample 800 observations
from OJ I use the sample function to take 800 from 1 through the total
number of rows in the dataset. The test is then taken as the rows not
included in this set of sampled rows.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>727</span><span class='op'>)</span>

<span class='va'>train_orange_juice</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/sample.html'>sample</a></span><span class='op'>(</span><span class='fl'>1</span><span class='op'>:</span><span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>OJ</span><span class='op'>)</span>, <span class='fl'>800</span>, replace <span class='op'>=</span> <span class='cn'>FALSE</span><span class='op'>)</span>

<span class='va'>OJ_train</span> <span class='op'>&lt;-</span> <span class='va'>OJ</span><span class='op'>[</span><span class='va'>train_orange_juice</span>,<span class='op'>]</span>

<span class='va'>OJ_test</span> <span class='op'>&lt;-</span> <span class='va'>OJ</span><span class='op'>[</span><span class='op'>-</span><span class='va'>train_orange_juice</span>,<span class='op'>]</span>
</code></pre>
</div>
</div>
<h4 id="part-b-2">Part (b)</h4>
<p><strong>Question:</strong> Fit a tree to the training data, with
Purchase as the response and the other variables as predictors. Use the
summary() function to produce summary statistics about the tree, and
describe the results obtained. What is the training error rate? How many
terminal nodes does the tree have?</p>
<p><strong>Answer:</strong> Using the training data below I fit a tree
using the tree function on the training subset. The training error rate
from the summary is 0.1475 and there are 8 terminal nodes.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>727</span><span class='op'>)</span>

<span class='va'>tree.OJ_train</span> <span class='op'>&lt;-</span> <span class='fu'>tree</span><span class='op'>(</span><span class='va'>Purchase</span> <span class='op'>~</span> <span class='va'>.</span>, <span class='va'>OJ</span>, subset <span class='op'>=</span> <span class='va'>train_orange_juice</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/base/summary.html'>summary</a></span><span class='op'>(</span><span class='va'>tree.OJ_train</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>
Classification tree:
tree(formula = Purchase ~ ., data = OJ, subset = train_orange_juice)
Variables actually used in tree construction:
[1] &quot;LoyalCH&quot;       &quot;PriceDiff&quot;     &quot;ListPriceDiff&quot; &quot;PctDiscMM&quot;    
Number of terminal nodes:  8 
Residual mean deviance:  0.7145 = 565.9 / 792 
Misclassification error rate: 0.1475 = 118 / 800 </code></pre>
</div>
<h4 id="part-c">Part (c)</h4>
<p><strong>Question:</strong> Type in the name of the tree object in
order to get a detailed text output. Pick one of the terminal nodes, and
interpret the information displayed.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>tree.OJ_train</span>
</code></pre>
</div>
<pre><code>node), split, n, deviance, yval, (yprob)
      * denotes terminal node

 1) root 800 1065.00 CH ( 0.61625 0.38375 )  
   2) LoyalCH &lt; 0.5036 344  407.30 MM ( 0.27907 0.72093 )  
     4) LoyalCH &lt; 0.276142 172  131.50 MM ( 0.12791 0.87209 )  
       8) LoyalCH &lt; 0.051325 62   10.24 MM ( 0.01613 0.98387 ) *
       9) LoyalCH &gt; 0.051325 110  107.30 MM ( 0.19091 0.80909 ) *
     5) LoyalCH &gt; 0.276142 172  235.10 MM ( 0.43023 0.56977 )  
      10) PriceDiff &lt; 0.05 69   60.54 MM ( 0.15942 0.84058 ) *
      11) PriceDiff &gt; 0.05 103  137.60 CH ( 0.61165 0.38835 ) *
   3) LoyalCH &gt; 0.5036 456  351.30 CH ( 0.87061 0.12939 )  
     6) LoyalCH &lt; 0.764572 188  215.70 CH ( 0.73936 0.26064 )  
      12) ListPriceDiff &lt; 0.235 74  102.60 MM ( 0.50000 0.50000 )  
        24) PctDiscMM &lt; 0.196196 54   71.19 CH ( 0.62963 0.37037 ) *
        25) PctDiscMM &gt; 0.196196 20   16.91 MM ( 0.15000 0.85000 ) *
      13) ListPriceDiff &gt; 0.235 114   76.72 CH ( 0.89474 0.10526 ) *
     7) LoyalCH &gt; 0.764572 268   85.39 CH ( 0.96269 0.03731 ) *</code></pre>
</div>
<p><strong>Answer:</strong> One of the terminal nodes is the 7th one
indicated, 7) LoyalCH &gt; 0.764572 268, 85.39 CH ( 0.96269 0.03731 )
this node indicates 6 attributes of the node the first, node), is
<strong>7)</strong> in this case. The next attribute is the split in the
data that it represents in this case split, which is when the variable
LoyalCH &gt; 0.764572 next is the n, or number of observations that
fulfill this attribute. Following this is the deviance of this
observation denoted as 85.39, yval is 0.96269, and finally (yprob) is
0.03731.</p>
<h4 id="part-d">Part (d)</h4>
<p><strong>Question:</strong> Create a plot of the tree, and interpret
the results.</p>
<div class="layout-chunk" data-layout="l-body">
<p><img src="ml-homework-2_files/figure-html5/unnamed-chunk-112-1.png" width="624" /></p>
</div>
<p><strong>Answer:</strong> The tree above indicates predicted
classification into 2 categories, either purchasing citrus hill or
minute maid using class proportions in our training data, each split
represents a distinction between observations in each predictor category
as determined by prior steps to eliminate the most classification error.
First Loyal CH, or customer brand loyalty for citrus hill is observed
and split to be above or below a loyalty of 0.5036, this split then,
again distinguishes loyal CH. On the 2nd node on the left loyal ch is
below 0.5036, it is then tested whether or not loyalty to CH is above or
below 0.276, if it is below this, it is then test on the third level
node on the far left whether or not loyalty CH is below or above
0.051325, in this case whether loyalty is below this or above it
(indicating it is between 0.051325 and 0.276) the customers will always
be classified as being fans of minute main. Continuing from the 2nd node
on the left this time we test LoyalCH above 0.276, this leads us to the
third node PriceDiff &lt; 0.05, in this case if the price difference is
between the two and CH loyalty is above 0.276, the customer is
categorized as buying CH, however if the loyalty to CH is 0.276, but the
price difference is less than 0.05 then the customers is categorized as
choosing MM. Going to the second node on the right, LoyalCH &lt; 0.764,
we categorize a customer as buying CH if their loyalty to the brand is
greater than 0.764. However if that node LoyalCH &lt; 0.764 is less than
the stated value then we look to ListPriceDiff, in this case LoyalCH is
between 0.50 and 0.764, this third node then predicts a customer as CH
if the listed price difference is above 0.235, if the list price
difference is less we move to PctDiscMM or the percentage discount for
MM, if the discount is above 0.196 the customer will choose MM, if it is
below they will be categorized as choosing CH.</p>
<h4 id="part-e">Part (e)</h4>
<p><strong>Question:</strong> Predict the response on the test data, and
produce a confusion matrix comparing the test labels to the predicted
test labels. What is the test error rate?</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>727</span><span class='op'>)</span>

<span class='va'>test.pred</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>tree.OJ_train</span>, <span class='va'>OJ_test</span>, type <span class='op'>=</span> <span class='st'>"class"</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/base/table.html'>table</a></span><span class='op'>(</span><span class='va'>test.pred</span>, <span class='va'>OJ_test</span><span class='op'>$</span><span class='va'>Purchase</span><span class='op'>)</span>  <span class='op'><a href='https://rdrr.io/pkg/DiagrammeR/man/pipe.html'>%&gt;%</a></span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">CH</th>
<th style="text-align: right;">MM</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">CH</td>
<td style="text-align: right;">144</td>
<td style="text-align: right;">40</td>
</tr>
<tr class="even">
<td style="text-align: left;">MM</td>
<td style="text-align: right;">16</td>
<td style="text-align: right;">70</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Answer:</strong> The error rate is the number of incorrectly
identified purchasers of orange juice in terms of their actual purcahse
compared to whether or not they were predicted to purchase it by the
model. It is calculated here as 0.2074074, or 20.7%, this is calculated
below as one minus the difference between correctly identified buyers
and incorrectly identified buyers.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='op'>(</span><span class='fl'>1</span><span class='op'>-</span><span class='op'>(</span><span class='fl'>144</span><span class='op'>+</span><span class='fl'>70</span><span class='op'>)</span><span class='op'>/</span><span class='op'>(</span><span class='fl'>144</span><span class='op'>+</span><span class='fl'>70</span><span class='op'>+</span><span class='fl'>40</span><span class='op'>+</span><span class='fl'>16</span><span class='op'>)</span> <span class='op'>)</span>  <span class='op'><a href='https://rdrr.io/pkg/DiagrammeR/man/pipe.html'>%&gt;%</a></span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.2074074</td>
</tr>
</tbody>
</table>
</div>
<h4 id="part-f">Part (f)</h4>
<p><strong>Question:</strong> Apply the cv.tree() function to the
training set in order to determine the optimal tree size.</p>
<p><strong>Answer:</strong> The dev, or deviation represents the error
rate. In this case it is lowest when size=8 and dev is 646.6050.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>727</span><span class='op'>)</span>

<span class='va'>cv.OJ</span> <span class='op'>&lt;-</span> <span class='fu'>cv.tree</span><span class='op'>(</span><span class='va'>tree.OJ_train</span><span class='op'>)</span>

<span class='va'>cv.OJ</span> 
</code></pre>
</div>
<pre><code>$size
[1] 8 7 6 5 4 3 2 1

$dev
[1]  646.6050  674.2620  673.7721  766.0959  770.2143  751.8258
[7]  772.1636 1066.2872

$k
[1]      -Inf  14.04513  14.48895  36.41322  36.93239  40.72147
[7]  50.20841 306.72764

$method
[1] &quot;deviance&quot;

attr(,&quot;class&quot;)
[1] &quot;prune&quot;         &quot;tree.sequence&quot;</code></pre>
</div>
<h4 id="part-g">Part (g)</h4>
<p><strong>Question:</strong> Produce a plot with tree size on the
x-axis and cross-validated classification error rate on the y-axis.</p>
<p><strong>Answer:</strong> Below I have plotted the tree size compared
to the classification error rate. As can be seen 8 is much lower than
the tree sizes that come before them in terms of error rate.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>727</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='va'>cv.OJ</span><span class='op'>$</span><span class='va'>size</span>, <span class='va'>cv.OJ</span><span class='op'>$</span><span class='va'>dev</span>, type <span class='op'>=</span> <span class='st'>"b"</span>, xlab <span class='op'>=</span> <span class='st'>"Tree Size"</span>, ylab<span class='op'>=</span><span class='st'>"Cross Validated Misclass"</span><span class='op'>)</span> 
</code></pre>
</div>
<p><img src="ml-homework-2_files/figure-html5/unnamed-chunk-116-1.png" width="624" /></p>
</div>
<h4 id="part-h">Part (h)</h4>
<p><strong>Question:</strong> Which tree size corresponds to the lowest
cross-validated classification error rate?</p>
<p><strong>Answer:</strong> It appears that the tree with the lowest
possible error is 8 in this case.</p>
<h4 id="part-i">Part (i)</h4>
<p><strong>Question:</strong> Produce a pruned tree corresponding to the
optimal tree size obtained using cross-validation. If cross-validation
does not lead to selection of a pruned tree, then create a pruned tree
with five terminal nodes.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>727</span><span class='op'>)</span>

<span class='va'>prune.OJ</span> <span class='op'>&lt;-</span> <span class='fu'>prune.misclass</span><span class='op'>(</span><span class='va'>tree.OJ_train</span>, best <span class='op'>=</span> <span class='fl'>8</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/base/summary.html'>summary</a></span><span class='op'>(</span><span class='va'>prune.OJ</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>
Classification tree:
tree(formula = Purchase ~ ., data = OJ, subset = train_orange_juice)
Variables actually used in tree construction:
[1] &quot;LoyalCH&quot;       &quot;PriceDiff&quot;     &quot;ListPriceDiff&quot; &quot;PctDiscMM&quot;    
Number of terminal nodes:  8 
Residual mean deviance:  0.7145 = 565.9 / 792 
Misclassification error rate: 0.1475 = 118 / 800 </code></pre>
</div>
<p><strong>Answer:</strong> In this case the misclassification error
rate is 0.1475 as indicated by the summary above.</p>
<h2 id="part-j">Part (j)</h2>
<p><strong>Question:</strong> Compare the training error rates between
the pruned and un-pruned trees. Which is higher?</p>
<p><strong>Answer:</strong> The training error rate in the pruned tree
is 0.1475, this is far lower than the unpruned rate of 0.2074074.</p>
<h4 id="part-k">Part (k)</h4>
<p><strong>Question:</strong> Compare the test error rates between the
pruned and unpruned trees. Which is higher?</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>727</span><span class='op'>)</span>

<span class='va'>prediction_pruned</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>prune.OJ</span>, <span class='va'>OJ_test</span>,
type <span class='op'>=</span> <span class='st'>"class"</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/base/table.html'>table</a></span><span class='op'>(</span><span class='va'>prediction_pruned</span>, <span class='va'>OJ_test</span><span class='op'>$</span><span class='va'>Purchase</span><span class='op'>)</span> <span class='op'><a href='https://rdrr.io/pkg/DiagrammeR/man/pipe.html'>%&gt;%</a></span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">CH</th>
<th style="text-align: right;">MM</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">CH</td>
<td style="text-align: right;">144</td>
<td style="text-align: right;">40</td>
</tr>
<tr class="even">
<td style="text-align: left;">MM</td>
<td style="text-align: right;">16</td>
<td style="text-align: right;">70</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Answer:</strong> Here we see the misclassification error rate
is 0.2074074, or about 20.7% this is the same as the prior rate.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='op'>(</span><span class='fl'>1</span><span class='op'>-</span><span class='op'>(</span><span class='fl'>144</span><span class='op'>+</span><span class='fl'>70</span><span class='op'>)</span><span class='op'>/</span><span class='op'>(</span><span class='fl'>144</span><span class='op'>+</span><span class='fl'>40</span><span class='op'>+</span><span class='fl'>16</span><span class='op'>+</span><span class='fl'>70</span><span class='op'>)</span><span class='op'>)</span>  <span class='op'><a href='https://rdrr.io/pkg/DiagrammeR/man/pipe.html'>%&gt;%</a></span> <span class='fu'>kable</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
<table>
<thead>
<tr class="header">
<th style="text-align: right;">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.2074074</td>
</tr>
</tbody>
</table>
</div>
<h3 id="possible-data-set-final-question">Possible Data Set Final
Question:</h3>
<p><strong>Chosen Dataset:</strong> For my final project I wanted to
combine machine learning techniques with a networks dataset to see if
certain models could be used on it. I am using data on conflict which I
am treating as a network with node and edge attributes, using these
attributes I think it would be interesting to see if it is possible to
use classification techniques like KNN, LDA, and logistic regression to
predict centrality and see what node and edge attributes contribute to
centrality ranking.</p>
<div class="sourceCode" id="cb40"><pre
class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>


<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom"></div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
